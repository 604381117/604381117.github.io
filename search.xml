<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Nachos-Lab3-同步与互斥机制模块实现]]></title>
    <url>%2F2019%2F05%2F14%2Fnachos-3-4-Lab3%2F</url>
    <content type="text"><![CDATA[源码获取https://github.com/icoty/nachos-3.4-Lab 内容一：总体概述本实习希望通过修改Nachos系统平台的底层源代码，达到“扩展同步机制，实现同步互斥实例”的目标。 内容二：任务完成情况任务完成列表（Y/N） Exercise1 Exercise2 Exercise3 Exercise4 Challenge1 Challenge2 Challenge3 第一部分 Y Y Y Y Y Y N 具体Exercise的完成情况Exercise1 调研调研Linux或Windows中采用的进程/线程调度算法。具体内容见课堂要求。 同步是指用于实现控制多个进程按照一定的规则或顺序访问某些系统资源的机制，进程间的同步方式有共享内存，套接字，管道，信号量，消息队列，条件变量；线程间的同步有套接字，消息队列，全局变量，条件变量，信号量。 互斥是指用于实现控制某些系统资源在任意时刻只能允许一个进程访问的机制。互斥是同步机制中的一种特殊情况。进程间的互斥方式有锁，信号量，条件变量；线程间的互斥方式有信号量，锁，条件变量。此外，通过硬件也能实现同步与互斥。 linux内核中提供的同步机制 原子操作 自旋锁 读写自旋锁 信号量 读写信号量 互斥量 完成变量 大内核锁 顺序锁 禁止抢占 顺序和屏障 Exercise2 源代码阅读code/threads/synch.h和code/threads/synch.cc：Condition和Lock仅仅声明了未定义；Semaphore既声明又定义了。 Semaphore有一个初值和一个等待队列，提供P、V操作： P操作：当value等于0时，将当前运行线程放入线程等待队列，当前进程进入睡眠状态，并切换到其他线程运行；当value大于0时，value–。 V操作：如果线程等待队列中有等待该信号量的线程，取出其中一个将其设置成就绪态，准备运行，value++。 Lock：Nachos中没有给出锁机制的实现，接口有获得锁(Acquire)和释放锁(Release)，他们都是原子操作。 Acquire：当锁处于BUSY态，进入睡眠状态。当锁处于FREE态，当前进程获得该锁，继续运行。 Release：释放锁（只能由拥有锁的线程才能释放锁），将锁的状态设置为FREE态，如果有其他线程等待该锁，将其中的一个唤醒，进入就绪态。 Condition：条件变量同信号量、锁机制不一样，条件变量没值。当一个线程需要的某种条件没有得到满足时，可以将自己作为一个等待条件变量的线程插入所有等待该条件变量的队列，只要条件一旦得到满足，该线程就会被唤醒继续运行。条件变量总是和锁机制一起使。主要接口Wait、Signal、BroadCast，这三个操作必须在当前线程获得一个锁的前提下，而且所有对一个条件变量进行的操作必须建立在同一个锁的前提下。 Wait(Lock *conditionLock)：线程等待在条件变量上，把线程放入条件变量的等待队列上。 Signal(Lock *conditionLock)：从条件变量的等待队列中唤醒一个等待该条件变量的线程。 BroadCast(Lock *conditionLock)：唤醒所有等待该条件变量的线程。 code/threads/synchlist.h和code/threads/synchlist.cc：利用锁、条件变量实现的一个消息队列，使多线程达到互斥访问和同步通信的目的，类内有一个Lock和List成员变量。提供了对List的Append()，Remove()和Mapcar()操作。每个操作都要先获得该锁，然后才能对List进行相应的操作。 Exercise3 实现锁和条件变量可以使用sleep和wakeup两个原语操作（注意屏蔽系统中断），也可以使用Semaphore作为唯一同步原语（不必自己编写开关中断的代码）。 这里选择用1值信号量实现锁功能，Lock添加成员变量lock和owner，请求锁和释放锁都必须关中断，Condition添加一个成员变量queue，用于存放所有等待在该条件变量上的线程。代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899// synch.h Lock声明部分class Lock &#123;……private: char* name; // for debugging // add by yangyu Semaphore *lock; Thread* owner;&#125;;class Condition &#123;……private: char* name; // add by yangyu List* queue;&#125;;// synch.cc Lock定义部分Lock::Lock(char* debugName) :lock(new Semaphore("lock", 1)),name(debugName),owner(NULL)&#123;&#125;Lock::~Lock() &#123; delete lock;&#125;bool Lock::isHeldByCurrentThread()&#123; return currentThread == owner;&#125;void Lock::Acquire() &#123; IntStatus prev = interrupt-&gt;SetLevel(IntOff); lock-&gt;P(); owner = currentThread; (void)interrupt-&gt;SetLevel(prev);&#125;void Lock::Release() &#123; IntStatus prev = interrupt-&gt;SetLevel(IntOff); ASSERT(currentThread == owner); lock-&gt;V(); owner = NULL; (void)interrupt-&gt;SetLevel(prev);&#125;// synch.cc Condition定义部分Condition::Condition(char* debugName):name(debugName),queue(new List)&#123; &#125;Condition::~Condition()&#123; &#125;void Condition::Wait(Lock* conditionLock) &#123; //ASSERT(FALSE); // 关中断 IntStatus prev = interrupt-&gt;SetLevel(IntOff); // 锁和信号量不同，谁加锁必须由谁解锁，因此做下判断 ASSERT(conditionLock-&gt;isHeldByCurrentThread()); // 进入睡眠前把锁的权限释放掉，然后放到等待队列，直到被唤醒时重新征用锁 conditionLock-&gt;Release(); queue-&gt;Append(currentThread); currentThread-&gt;Sleep(); conditionLock-&gt;Acquire(); (void)interrupt-&gt;SetLevel(prev);&#125;void Condition::Signal(Lock* conditionLock) &#123; IntStatus prev = interrupt-&gt;SetLevel(IntOff); ASSERT(conditionLock-&gt;isHeldByCurrentThread()); if(!queue-&gt;IsEmpty()) &#123; // 唤醒一个等待的线程，挂入倒就绪队列中 Thread* next = (Thread*)queue-&gt;Remove(); scheduler-&gt;ReadyToRun(next); &#125; (void)interrupt-&gt;SetLevel(prev);&#125;void Condition::Broadcast(Lock* conditionLock) &#123; IntStatus prev = interrupt-&gt;SetLevel(IntOff); ASSERT(conditionLock-&gt;isHeldByCurrentThread()); // 唤醒等待在该条件变量上的所有线程 while(!queue-&gt;IsEmpty()) &#123; Signal(conditionLock); &#125; (void)interrupt-&gt;SetLevel(prev);&#125; Exercise4 实现同步互斥实例基于Nachos中的信号量、锁和条件变量，采用两种方式实现同步和互斥机制应用（其中使用条件变量实现同步互斥机制为必选题目）。具体可选择“生产者-消费者问题”、“读者-写者问题”、“哲学家就餐问题”、“睡眠理发师问题”等。（也可选择其他经典的同步互斥问题）。 生产者-消费者问题(Condition实现)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121// threadtest.cc// 条件变量实现生产者消费者问题Condition* condc = new Condition("ConsumerCondition");Condition* condp = new Condition("ProducerCondition");Lock* pcLock = new Lock("producerConsumerLock");int shareNum = 0; // 共享内容，生产+1，消费-1，互斥访问// lab3 条件变量实现生产者消费者问题void Producer1(int val)&#123; while(1)&#123; pcLock-&gt;Acquire(); // 缓冲区已满则等待在条件变量上，停止生产，等待消费后再生产 while(shareNum &gt;= N)&#123; printf("Product alread full:[%d],threadId:[%d],wait consumer.\n",shareNum,currentThread-&gt;getThreadId()); condp-&gt;Wait(pcLock); &#125; printf("name:[%s],threadId:[%d],before:[%d],after:[%d]\n",currentThread-&gt;getName(),currentThread-&gt;getThreadId(),shareNum,shareNum+1); ++shareNum; // 生产一个通知可消费，唤醒一个等待在condc上的消费者 condc-&gt;Signal(pcLock); pcLock-&gt;Release(); sleep(val); &#125;&#125;void Customer1(int val)&#123; while(1)&#123; pcLock-&gt;Acquire(); // 为零表示已经消费完毕,等待在条件变量上，等待生产后再消费 while(shareNum &lt;= 0)&#123; printf("--&gt;Product alread empty:[%d],threadId:[%d],wait producer.\n",shareNum,currentThread-&gt;getThreadId()); condc-&gt;Wait(pcLock); &#125; printf("--&gt;name:[%s],threadId:[%d],before:[%d],after:[%d]\n",currentThread-&gt;getName(),currentThread-&gt;getThreadId(),shareNum,shareNum-1); --shareNum; // 消费一个后通知生产者缓冲区不为满，可以生产 condp-&gt;Signal(pcLock); pcLock-&gt;Release(); //sleep(val); &#125;&#125;void ThreadProducerConsumerTest1()&#123; DEBUG('t', "Entering ThreadProducerConsumerTest1"); // 两个生产者循环生产 Thread* p1 = new Thread("Producer1"); Thread* p2 = new Thread("Producer2"); p1-&gt;Fork(Producer1, 1); p2-&gt;Fork(Producer1, 3); // 两个消费者循环消费 Thread* c1 = new Thread("Consumer1"); Thread* c2 = new Thread("Consumer2"); c1-&gt;Fork(Customer1, 1); c2-&gt;Fork(Customer1, 2);&#125;void ThreadTest()&#123; switch (testnum) &#123; case 1: ThreadTest1(); break; case 2: ThreadCountLimitTest(); break; case 3: ThreadPriorityTest(); break; case 4: ThreadProducerConsumerTest(); break; case 5: ThreadProducerConsumerTest1(); break; case 6: barrierThreadTest(); break; case 7: readWriteThreadTest(); break; default: printf("No test specified.\n"); break; &#125;&#125;// 运行结果，需要-rs，否则可能没有中断发生，永远是一个线程在运行// 通过结果可以明确看出生产前和生产后，消费前和消费后的数值变化// 可以通过修改Producer1和Consumer1内的sleep(val)来调整不同的速度// 当生产满了会停止生产，消费完了也会停止消费root@yangyu-ubuntu-32:/mnt/nachos-3.4-Lab/nachos-3.4/threads# root@yangyu-ubuntu-32:/mnt/nachos-3.4-Lab/nachos-3.4/threads# ./nachos -rs -q 5name:[Producer1],threadId:[1],before:[0],after:[1]name:[Producer2],threadId:[2],before:[1],after:[2]--&gt;name:[Consumer1],threadId:[3],before:[2],after:[1]name:[Producer1],threadId:[1],before:[1],after:[2]--&gt;name:[Consumer2],threadId:[4],before:[2],after:[1]name:[Producer2],threadId:[2],before:[1],after:[2]--&gt;name:[Consumer1],threadId:[3],before:[2],after:[1]name:[Producer1],threadId:[1],before:[1],after:[2]--&gt;name:[Consumer2],threadId:[4],before:[2],after:[1]name:[Producer2],threadId:[2],before:[1],after:[2]--&gt;name:[Consumer1],threadId:[3],before:[2],after:[1]--&gt;name:[Consumer2],threadId:[4],before:[1],after:[0]name:[Producer1],threadId:[1],before:[0],after:[1]name:[Producer2],threadId:[2],before:[1],after:[2]--&gt;name:[Consumer1],threadId:[3],before:[2],after:[1]name:[Producer2],threadId:[2],before:[1],after:[2]name:[Producer1],threadId:[1],before:[2],after:[3]--&gt;name:[Consumer2],threadId:[4],before:[3],after:[2]--&gt;name:[Consumer1],threadId:[3],before:[2],after:[1]name:[Producer2],threadId:[2],before:[1],after:[2]name:[Producer1],threadId:[1],before:[2],after:[3]--&gt;name:[Consumer2],threadId:[4],before:[3],after:[2]--&gt;name:[Consumer1],threadId:[3],before:[2],after:[1]name:[Producer2],threadId:[2],before:[1],after:[2]^CCleaning up...root@yangyu-ubuntu-32:/mnt/nachos-3.4-Lab/nachos-3.4/threads# 生产者-消费者问题(Semaphore实现)12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485// threadtest.cc// 信号量解决生产者消费者问题#define N 1024 // 缓冲区大小Semaphore* empty = new Semaphore("emptyBuffer", N);Semaphore* mutex = new Semaphore("lockSemaphore", 1);Semaphore* full = new Semaphore("fullBuffer", 0);int msgQueue = 0;void Producer(int val)&#123; while(1) &#123; empty-&gt;P(); mutex-&gt;P(); if(msgQueue &gt;= N)&#123; // 已经满了则停止生产 printf("--&gt;Product alread full:[%d],wait consumer.",msgQueue); &#125;else&#123; printf("--&gt;name:[%s],threadId:[%d],before:[%d],after:[%d]\n",\ currentThread-&gt;getName(),currentThread-&gt;getThreadId(),msgQueue,msgQueue+1); ++msgQueue; &#125; mutex-&gt;V(); full-&gt;V(); sleep(val); // 休息下再生产 &#125;&#125;void Customer(int val)&#123; while(1) &#123; full-&gt;P(); mutex-&gt;P(); if(msgQueue &lt;= 0)&#123; printf("Product alread empty:[%d],wait Producer.",msgQueue); &#125;else&#123; printf("name:[%s] threadId:[%d],before:[%d],after:[%d]\n",\ currentThread-&gt;getName(),currentThread-&gt;getThreadId(),msgQueue,msgQueue-1); --msgQueue; &#125; mutex-&gt;V(); empty-&gt;V(); sleep(val); // 休息下再消费 &#125;&#125;void ThreadProducerConsumerTest()&#123; DEBUG('t', "Entering ThreadProducerConsumerTest"); // 两个生产者 Thread* p1 = new Thread("Producer1"); Thread* p2 = new Thread("Producer2"); p1-&gt;Fork(Producer, 1); p2-&gt;Fork(Producer, 3); // 两个消费者，可以关掉一个消费者，查看生产速率和消费速率的变化 Thread* c1 = new Thread("Consumer1"); //Thread* c2 = new Thread("Consumer2"); c1-&gt;Fork(Customer, 1); //c2-&gt;Fork(Customer, 2);&#125;// 通过结果可以明确看出生产前和生产后，消费前和消费后的数值变化// 可以通过修改Producer和Consumer内的sleep(val)来调整不同的速度// 当生产满了会停止生产，消费完了也会停止消费root@yangyu-ubuntu-32:/mnt/nachos-3.4-Lab/nachos-3.4/threads# root@yangyu-ubuntu-32:/mnt/nachos-3.4-Lab/nachos-3.4/threads# ./nachos -rs -q 4--&gt;name:[Producer1],threadId:[1],before:[0],after:[1]--&gt;name:[Producer2],threadId:[2],before:[1],after:[2]name:[Consumer1] threadId:[3],before:[2],after:[1]--&gt;name:[Producer1],threadId:[1],before:[1],after:[2]--&gt;name:[Producer2],threadId:[2],before:[2],after:[3]--&gt;name:[Producer1],threadId:[1],before:[3],after:[4]name:[Consumer1] threadId:[3],before:[4],after:[3]--&gt;name:[Producer2],threadId:[2],before:[3],after:[4]name:[Consumer1] threadId:[3],before:[4],after:[3]--&gt;name:[Producer1],threadId:[1],before:[3],after:[4]--&gt;name:[Producer2],threadId:[2],before:[4],after:[5]name:[Consumer1] threadId:[3],before:[5],after:[4]--&gt;name:[Producer1],threadId:[1],before:[4],after:[5]--&gt;name:[Producer2],threadId:[2],before:[5],after:[6]--&gt;name:[Producer1],threadId:[1],before:[6],after:[7]--&gt;name:[Producer2],threadId:[2],before:[7],after:[8]name:[Consumer1] threadId:[3],before:[8],after:[7]^CCleaning up...root@yangyu-ubuntu-32:/mnt/nachos-3.4-Lab/nachos-3.4/threads# Challenge1 实现barrier(至少选做一个Challenge)可以使用Nachos 提供的同步互斥机制（如条件变量）来实现barrier，使得当且仅当若干个线程同时到达某一点时方可继续执行。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566// threadtest.cc// 条件变量实现barrierCondition* barrCond = new Condition("BarrierCond");Lock* barrLock = new Lock("BarrierLock");int barrierCnt = 0;// 当且仅当barrierThreadNum个线程同时到达时才能往下运行const int barrierThreadNum = 5; void barrierFun(int num)&#123; /*while(1)*/ &#123; barrLock-&gt;Acquire(); ++barrierCnt; if(barrierCnt == barrierThreadNum)&#123; // 最后一个线程到达后判断，条件满足则发送一个广播信号 // 唤醒等待在该条件变量上的所有线程 printf("threadName:[%s%d],barrierCnt:[%d],needCnt:[%d],Broadcast.\n",\ currentThread-&gt;getName(),num,barrierCnt,barrierThreadNum); barrCond-&gt;Broadcast(barrLock); barrLock-&gt;Release(); &#125;else&#123; // 每一个线程都执行判断，若条件不满足，线程等待在条件变量上 printf("threadName:[%s%d],barrierCnt:[%d],needCnt:[%d],Wait.\n",\ currentThread-&gt;getName(),num,barrierCnt,barrierThreadNum); barrCond-&gt;Wait(barrLock); barrLock-&gt;Release(); &#125; printf("threadName:[%s%d],continue to run.\n", currentThread-&gt;getName(),num); &#125;&#125;void barrierThreadTest()&#123; DEBUG('t', "Entering barrierThreadTest"); for(int i = 0; i &lt; barrierThreadNum; ++i)&#123; Thread* t = new Thread("barrierThread"); t-&gt;Fork(barrierFun,i+1); &#125;&#125;// 运行结果，当第五个线程进入后判断条件满足，唤醒所有线程root@yangyu-ubuntu-32:/mnt/nachos-3.4-Lab/nachos-3.4/threads# root@yangyu-ubuntu-32:/mnt/nachos-3.4-Lab/nachos-3.4/threads# ./nachos -rs -q 6threadName:[barrierThread1],barrierCnt:[1],needCnt:[5],Wait.threadName:[barrierThread2],barrierCnt:[2],needCnt:[5],Wait.threadName:[barrierThread3],barrierCnt:[3],needCnt:[5],Wait.threadName:[barrierThread4],barrierCnt:[4],needCnt:[5],Wait.threadName:[barrierThread5],barrierCnt:[5],needCnt:[5],Broadcast.threadName:[barrierThread5],continue to run.threadName:[barrierThread2],continue to run.threadName:[barrierThread1],continue to run.threadName:[barrierThread4],continue to run.threadName:[barrierThread3],continue to run.No threads ready or runnable, and no pending interrupts.Assuming the program completed.Machine halting!Ticks: total 814, idle 4, system 810, user 0Disk I/O: reads 0, writes 0Console I/O: reads 0, writes 0Paging: faults 0Network I/O: packets received 0, sent 0Cleaning up...root@yangyu-ubuntu-32:/mnt/nachos-3.4-Lab/nachos-3.4/threads# Challenge2 实现read/write lock基于Nachos提供的lock(synch.h和synch.cc)，实现read/write lock。使得若干线程可以同时读取某共享数据区内的数据，但是在某一特定的时刻，只有一个线程可以向该共享数据区写入数据。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091// threadtest.cc// Lab3 锁实现读者写者问题int rCnt = 0; // 记录读者数量Lock* rLock = new Lock("rlock");// 必须用信号量，不能用锁，因为锁只能由加锁的线程解锁Semaphore* wLock = new Semaphore("wlock",1); int bufSize = 0;// Lab3 锁实现读者写者问题void readFunc(int num)&#123; while(1) &#123; rLock-&gt;Acquire(); ++rCnt; // 如果是第一个读者进入，需要竞争1值信号量wLock，竞争成功才能进入临界区 // 一旦竞争到wLock，由最后一个读者出临界区后释放，保证了读者优先 if(rCnt == 1)&#123; wLock-&gt;P(); &#125; rLock-&gt;Release(); if(0 == bufSize)&#123; // 没有数据可读 printf("threadName:[%s],bufSize:[%d],current not data.\n",currentThread-&gt;getName(),bufSize); &#125;else&#123; // 读取数据 printf("threadName:[%s],bufSize:[%d],exec read operation.\n",currentThread-&gt;getName(),bufSize); &#125; rLock-&gt;Acquire(); --rCnt; // 最后一个读者释放wLock if(rCnt == 0)&#123; wLock-&gt;V(); &#125; rLock-&gt;Release(); currentThread-&gt;Yield(); sleep(num); &#125;&#125;void writeFunc(int num)&#123; while(1) &#123; wLock-&gt;P(); ++bufSize; printf("writerThread:[%s],before:[%d],after:[%d]\n", currentThread-&gt;getName(), bufSize, bufSize+1); wLock-&gt;V(); currentThread-&gt;Yield(); sleep(num); &#125;&#125;void readWriteThreadTest()&#123; DEBUG('t', "Entering readWriteThreadTest"); Thread * r1 = new Thread("read1"); Thread * r2 = new Thread("read2"); Thread * r3 = new Thread("read3"); Thread * w1 = new Thread("write1"); Thread * w2 = new Thread("write2"); // 3个读者2个写者 r1-&gt;Fork(readFunc,1); w1-&gt;Fork(writeFunc,1); r2-&gt;Fork(readFunc,1); w2-&gt;Fork(writeFunc,1); r3-&gt;Fork(readFunc,1);&#125;// 运行结果，第一个读者进入无数据可读// 可以发现读操作比写操作多// 一旦开始读，就要等所有线程读取完毕后，写线程才进入root@yangyu-ubuntu-32:/mnt/nachos-3.4-Lab/nachos-3.4/threads# root@yangyu-ubuntu-32:/mnt/nachos-3.4-Lab/nachos-3.4/threads# ./nachos -rs -q 7threadName:[read1],Val:[0],current not data.writerThread:[write1],before:[0],after:[1]writerThread:[write2],before:[1],after:[2]writerThread:[write1],before:[2],after:[3]writerThread:[write2],before:[3],after:[4]threadName:[read2],readVal:[4],exec read operation.threadName:[read1],readVal:[4],exec read operation.threadName:[read3],readVal:[4],exec read operation.writerThread:[write1],before:[4],after:[5]threadName:[read2],readVal:[5],exec read operation.threadName:[read3],readVal:[5],exec read operation.threadName:[read2],readVal:[5],exec read operation.threadName:[read3],readVal:[5],exec read operation.threadName:[read2],readVal:[5],exec read operation.threadName:[read3],readVal:[5],exec read operation.threadName:[read1],readVal:[5],exec read operation.writerThread:[write2],before:[5],after:[6]writerThread:[write1],before:[6],after:[7]^CCleaning up...root@yangyu-ubuntu-32:/mnt/nachos-3.4-Lab/nachos-3.4/threads# 内容三：遇到的困难以及解决方法困难1刚开始没有加-rs参数，导致永远都只有一个线程在运行，原因是没有中断发生，运行的线程永远在执行循环体，加-rs参数，会在一个固定的时间短内发一个时钟中断，然后调度其他线程运行。 内容四：收获及感想可以说实际操作后，对信号量，条件变量的应用更加清晰了。 内容五：对课程的意见和建议暂无。 内容六：参考文献https://blog.csdn.net/FreeeLinux/article/details/54267446#原子操作]]></content>
      <categories>
        <category>同步机制</category>
        <category>互斥机制</category>
      </categories>
      <tags>
        <tag>锁实现</tag>
        <tag>信号量</tag>
        <tag>条件变量实现</tag>
        <tag>生产者消费者问题</tag>
        <tag>读者写者问题</tag>
        <tag>Barrier实现</tag>
        <tag>Nachos-3.4</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nachos-Lab2-线程调度模块实现]]></title>
    <url>%2F2019%2F05%2F14%2Fnachos-3-4-Lab2%2F</url>
    <content type="text"><![CDATA[源码获取https://github.com/icoty/nachos-3.4-Lab 内容一：总体概述本实习希望通过修改Nachos系统平台的底层源代码，达到“扩展调度算法”的目标。本次实验主要是要理解Timer、Scheduler和Interrupt之间的关系，从而理解线程之间是如何进行调度的。 内容二：任务完成情况任务完成列表（Y/N） Exercise1 Exercise2 Exercise3 Challenge1 第一部分 Y Y Y Y 具体Exercise的完成情况Exercise1 调研调研Linux或Windows中采用的进程/线程调度算法。具体内容见课堂要求。 linux-4.19.23进程调度策略：SCHED_OTHER分时调度策略，SCHED_FIFO实时调度策略（先到先服务），SCHED_RR实时调度策略（时间片轮转）。 RR调度和FIFO调度的进程属于实时进程，以分时调度的进程是非实时进程。 当实时进程准备就绪后，如果当前cpu正在运行非实时进程，则实时进程立即抢占非实时进程。 RR进程和FIFO进程都采用实时优先级做为调度的权值标准，RR是FIFO的一个延伸。FIFO时，如果两个进程的优先级一样，则这两个优先级一样的进程具体执行哪一个是由其在队列中的位置决定的，这样导致一些不公正性(优先级是一样的，为什么要让你一直运行?)，如果将两个优先级一样的任务的调度策略都设为RR，则保证了这两个任务可以循环执行，保证了公平。 内核代码：内核为每个cpu维护一个进程就绪队列，cpu只调度由其维护的队列上的进程： vi linux-4.19.23/kernel/sched/core.c：123456……#define CREATE_TRACE_POINTS#include &lt;trace/events/sched.h&gt;DEFINE_PER_CPU_SHARED_ALIGNED(struct rq, runqueues);…… ​ vi linux-4.19.23/kernel/sched/sched.h：123456789101112131415161718192021222324252627282930313233/* * This is the main, per-CPU runqueue data structure. * * Locking rule: those places that want to lock multiple runqueues * (such as the load balancing or the thread migration code), lock * acquire operations must be ordered by ascending &amp;runqueue. */struct rq &#123; /* runqueue lock: */ raw_spinlock_t lock; // 锁保证互斥访问runqueue …… struct cfs_rq cfs; // 所有普通进程的集合，采用cfs调度策略 struct rt_rq rt; // 所有实时进程的集合，采用实时调度策略 struct dl_rq dl; // struct dl_rq空闲进程集合 ……&#125;;// cfs_rq就绪队列是一棵红黑树。/* CFS-related fields in a runqueue */struct cfs_rq &#123; …… struct rb_root_cached tasks_timeline; // 红黑树的树根 /* * 'curr' points to currently running entity on this cfs_rq. * It is set to NULL otherwise (i.e when none are currently running). */ struct sched_entity *curr; // 指向当前正运行的进程 struct sched_entity *next; // 指向将被唤醒的进程 struct sched_entity *last; // 指向唤醒next进程的进程 struct sched_entity *skip; ……&#125;; ​ vi linux-4.19.23/include/linux/sched.h：实时进程调度实体struct sched_rt_entity，双向链表组织形式；空闲进程调度实体struct sched_dl_entity，红黑树组织形式；普通进程的调度实体sched_entity，每个进程描述符中均包含一个该结构体变量，该结构体有两个作用： 包含有进程调度的信息（比如进程的运行时间，睡眠时间等等，调度程序参考这些信息决定是否调度进程）； 使用该结构体来组织进程，struct rb_node类型结构体变量run_node是红黑树节点，struct sched_entity调度实体将被组织成红黑树的形式，同时意味着普通进程也被组织成红黑树的形式。parent指向了当前实体的上一级实体，cfs_rq指向了该调度实体所在的就绪队列。my_q指向了本实体拥有的就绪队列（调度组），该调度组（包括组员实体）属于下一个级别，和本实体不在同一个级别，该调度组中所有成员实体的parent域指向了本实体，depth代表了此队列（调度组）的深度，每个调度组都比其parent调度组深度大1。内核依赖my_q域实现组调度。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546……// 普通进程的调度实体sched_entity，使用红黑树组织struct sched_entity &#123; /* For load-balancing: */ struct load_weight load; unsigned long runnable_weight; struct rb_node run_node; // 红黑树节点 struct list_head group_node; unsigned int on_rq; ……#ifdef CONFIG_FAIR_GROUP_SCHED int depth; struct sched_entity *parent; // 当前节点的父节点 /* rq on which this entity is (to be) queued: */ struct cfs_rq *cfs_rq; // 当前节点所在的就绪队列 /* rq "owned" by this entity/group: */ struct cfs_rq *my_q;#endif ……&#125;;// 实时进程调度实体，采用双向链表组织struct sched_rt_entity &#123; struct list_head run_list; // 链表组织 unsigned long timeout; unsigned long watchdog_stamp; unsigned int time_slice; unsigned short on_rq; unsigned short on_list; struct sched_rt_entity *back;#ifdef CONFIG_RT_GROUP_SCHED struct sched_rt_entity *parent; /* rq on which this entity is (to be) queued: */ struct rt_rq *rt_rq; // 当前节点所在的就绪队列 /* rq "owned" by this entity/group: */ struct rt_rq *my_q;#endif&#125; __randomize_layout;// 空闲进程调度实体，采用红黑树组织struct sched_dl_entity &#123; struct rb_node rb_node; ……&#125;;…… ​ vi linux-4.19.23/kernel/sched/sched.h：内核声明了一个调度类sched_class的结构体类型，用来实现不同的调度策略，可以看到该结构体成员都是函数指针，这些指针指向的函数就是调度策略的具体实现，所有和进程调度有关的函数都直接或者间接调用了这些成员函数，来实现进程调度。此外，每个进程描述符中都包含一个指向该结构体类型的指针sched_class，指向了所采用的调度类。 12345678910111213……struct sched_class &#123; const struct sched_class *next; void (*enqueue_task) (struct rq *rq, struct task_struct *p, int flags); void (*dequeue_task) (struct rq *rq, struct task_struct *p, int flags); void (*yield_task) (struct rq *rq); bool (*yield_to_task)(struct rq *rq, struct task_struct *p, bool preempt); void (*check_preempt_curr)(struct rq *rq, struct task_struct *p, int flags); ……&#125;;…… Exercise2 源代码阅读code/threads/scheduler.h和code/threads/scheduler.cc：scheduler类是nachos中的进程调度器，维护了一个挂起的中断队列，通过FIFO进行调度。 void ReadyToRun(Thread* thread)；设置线程状态为READY，并放入就绪队列readyList。 Thread* FindNextToRun(int source); 从就绪队列中取出下一个上CPU的线程，实现基于优先级的抢占式调度和FIFO调度。 void Run(Thread* nextThread); 把下CPU的线程的寄存器和堆栈信息从CPU保存到线程本身的寄存器数据结构中， 执行线程切换，把上CPU的线程的寄存器和堆栈信息从线程本身的寄存器中拷贝到CPU的寄存器中，运行新线程。 code/threads/switch.s：switch.s模拟内容是汇编代码，负责CPU上进程的切换。切换过程中，首先保存当前进程的状态，然后恢复新运行进程的状态，之后切换到新进程的栈空间，开始运行新进程。 code/machine/timer.h和code/machine/timer.cc：Timer类用以模拟硬件的时间中断。在TimerExired中，会调用TimeOfNextInterrupt，计算出下次时间中断的时间，并将中断插入中断队列中。初始化时会调用TimerExired，然后每次中断处理函数中都会调用一次TimerExired，从而时间系统时间一步步向前走。需要说明的是，在运行nachos时加入-rs选项，会初始化一个随机中断的Timer。当然你也可以自己声明一个非随机的Timer，每隔固定的时间片执行中断。时间片大小的定义位于ststs.h中，每次开关中断会调用OneTick()，当Ticks数目达到时间片大小时，会出发一次时钟中断。 Exercise3 线程调度算法扩展扩展线程调度算法，实现基于优先级的抢占式调度算法。 思路：更改Thread类，加入priority成员变量，同时更改初始化函数对其初始化，并完成对应的set和get函数。scheduler中的FindNextToRun负责找到下一个运行的进程，默认是FIFO，找到队列最开始时的线程返回。我们现在要实现的是根据优先级来返回，仅需将插入readyList队列的方法按照优先级从高到低顺序插入SortedInsert，那么插入时会维护队列中的Thread按照优先级排序，每次依旧从头取出第一个，即为优先级最高的队列。抢占式调度则需要在每次中断发生时尝试进行进程切换，如果有优先级更高的进程，则运行高优先级进程。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125// 基于优先级的可抢占式调度策略和FIFO调度策略Thread * Scheduler::FindNextToRun (bool bySleep)&#123; // called by threadsleep，直接调度，不用判断时间片 if(bySleep)&#123; lastSwitchTick = stats-&gt;systemTicks; return (Thread *)readyList-&gt;SortedRemove(NULL); // 与Remove()等价，都是从队头取 &#125;else&#123; int ticks = stats-&gt;systemTicks - lastSwitchTick; // 这里设置了运行的最短时间TimerSlice，防止频繁切换消耗CPU资源 // 测试优先级抢占调度时需要屏蔽这句，因为调用Yield()的线程运行时间很短 // 会直接返回NULL /*if(ticks &lt; TimerSlice)&#123; // 不用切换 return NULL; &#125;else*/&#123; if(readyList-&gt;IsEmpty())&#123; return NULL; &#125; Thread * next = (Thread *)readyList-&gt;SortedRemove(NULL);// 基于优先级可抢占调度策略,自己添加的宏，Makefile编译添加： -DSCHED_PRIORITY#ifdef SCHED_PRIORITY // nextThread优先级高于当前线程则切换，否则不切换 if(next-&gt;getPriority() &lt; currentThread-&gt;getPriority())&#123; lastSwitchTick = stats-&gt;systemTicks; return next; &#125;else&#123; readyList-&gt;SortedInsert(next, next-&gt;getPriority()); return NULL; &#125;#else // FIFO策略需要取消Makefile编译选项：-DSCHED_PRIORITY lastSwitchTick = stats-&gt;systemTicks; return next;#endif &#125; &#125;&#125;// 线程主动让出cpu,在FIFO调度策略下能够看到多个线程按顺序运行void SimpleThread(int which)&#123; for (int num = 0; num &lt; 5; num++) &#123; int ticks = stats-&gt;systemTicks - scheduler-&gt;getLastSwitchTick(); printf("userId=%d,threadId=%d,prio=%d,loop:%d,lastSwitchTick=%d,systemTicks=%d,usedTicks=%d,TimerSlice=%d\n",currentThread-&gt;getUserId(),currentThread-&gt;getThreadId(),currentThread-&gt;getPriority(),num,scheduler-&gt;getLastSwitchTick(),stats-&gt;systemTicks,ticks,TimerSlice); // 时间片轮转算法，判断时间片是否用完， // 如果用完主动让出cpu，针对nachos内核线程算法 /*if(ticks &gt;= TimerSlice)&#123; //printf("threadId=%d Yield\n",currentThread-&gt;getThreadId()); currentThread-&gt;Yield(); &#125;*/ // 非抢占模式下，多个线程同时执行该接口的话，会交替执行，交替让出cpu // 基于优先级抢占模式下，优先级高的线程运行结束后才调度低优先级线程 currentThread-&gt;Yield(); &#125;&#125;threadtest.cc:// 创建四个线程，加上主线程共五个，优先值越小优先级越高void ThreadPriorityTest()&#123; Thread* t1 = new Thread("forkThread1", 1); printf("--&gt;name=%s,threadId=%d\n",t1-&gt;getName(),t1-&gt;getThreadId()); t1-&gt;Fork(SimpleThread, (void*)1); Thread* t2 = new Thread("forkThread2", 2); printf("--&gt;name=%s,threadId=%d\n",t2-&gt;getName(),t2-&gt;getThreadId()); t2-&gt;Fork(SimpleThread, (void*)2); Thread* t3 = new Thread("forkThread3", 3); printf("--&gt;name=%s,threadId=%d\n",t3-&gt;getName(),t3-&gt;getThreadId()); t3-&gt;Fork(SimpleThread, (void*)3); Thread* t4 = new Thread("forkThread4", 4); printf("--&gt;name=%s,threadId=%d\n",t4-&gt;getName(),t4-&gt;getThreadId()); t4-&gt;Fork(SimpleThread, (void*)4); currentThread-&gt;Yield(); SimpleThread(0);&#125;// 运行结果，优先级1最高，最先执行完，其次是优先为2的线程，直到所有线程结束root@yangyu-ubuntu-32:/mnt/nachos-3.4-Lab/nachos-3.4/threads# ./nachos -q 3--&gt;name=forkThread1,threadId=1--&gt;name=forkThread2,threadId=2--&gt;name=forkThread3,threadId=3--&gt;name=forkThread4,threadId=4userId=0,threadId=1,prio=1,loop:0,lastSwitchTick=50,systemTicks=60,usedTicks=10,TimerSlice=30userId=0,threadId=1,prio=1,loop:1,lastSwitchTick=50,systemTicks=70,usedTicks=20,TimerSlice=30userId=0,threadId=1,prio=1,loop:2,lastSwitchTick=50,systemTicks=80,usedTicks=30,TimerSlice=30userId=0,threadId=1,prio=1,loop:3,lastSwitchTick=50,systemTicks=90,usedTicks=40,TimerSlice=30userId=0,threadId=1,prio=1,loop:4,lastSwitchTick=50,systemTicks=100,usedTicks=50,TimerSlice=30userId=0,threadId=2,prio=2,loop:0,lastSwitchTick=110,systemTicks=120,usedTicks=10,TimerSlice=30userId=0,threadId=2,prio=2,loop:1,lastSwitchTick=110,systemTicks=130,usedTicks=20,TimerSlice=30userId=0,threadId=2,prio=2,loop:2,lastSwitchTick=110,systemTicks=140,usedTicks=30,TimerSlice=30userId=0,threadId=2,prio=2,loop:3,lastSwitchTick=110,systemTicks=150,usedTicks=40,TimerSlice=30userId=0,threadId=2,prio=2,loop:4,lastSwitchTick=110,systemTicks=160,usedTicks=50,TimerSlice=30userId=0,threadId=3,prio=3,loop:0,lastSwitchTick=170,systemTicks=180,usedTicks=10,TimerSlice=30userId=0,threadId=3,prio=3,loop:1,lastSwitchTick=170,systemTicks=190,usedTicks=20,TimerSlice=30userId=0,threadId=3,prio=3,loop:2,lastSwitchTick=170,systemTicks=200,usedTicks=30,TimerSlice=30userId=0,threadId=3,prio=3,loop:3,lastSwitchTick=170,systemTicks=210,usedTicks=40,TimerSlice=30userId=0,threadId=3,prio=3,loop:4,lastSwitchTick=170,systemTicks=220,usedTicks=50,TimerSlice=30userId=0,threadId=4,prio=4,loop:0,lastSwitchTick=230,systemTicks=240,usedTicks=10,TimerSlice=30userId=0,threadId=4,prio=4,loop:1,lastSwitchTick=230,systemTicks=250,usedTicks=20,TimerSlice=30userId=0,threadId=4,prio=4,loop:2,lastSwitchTick=230,systemTicks=260,usedTicks=30,TimerSlice=30userId=0,threadId=4,prio=4,loop:3,lastSwitchTick=230,systemTicks=270,usedTicks=40,TimerSlice=30userId=0,threadId=4,prio=4,loop:4,lastSwitchTick=230,systemTicks=280,usedTicks=50,TimerSlice=30userId=0,threadId=0,prio=6,loop:0,lastSwitchTick=290,systemTicks=300,usedTicks=10,TimerSlice=30userId=0,threadId=0,prio=6,loop:1,lastSwitchTick=290,systemTicks=310,usedTicks=20,TimerSlice=30userId=0,threadId=0,prio=6,loop:2,lastSwitchTick=290,systemTicks=320,usedTicks=30,TimerSlice=30userId=0,threadId=0,prio=6,loop:3,lastSwitchTick=290,systemTicks=330,usedTicks=40,TimerSlice=30userId=0,threadId=0,prio=6,loop:4,lastSwitchTick=290,systemTicks=340,usedTicks=50,TimerSlice=30No threads ready or runnable, and no pending interrupts.Assuming the program completed.Machine halting!Ticks: total 350, idle 0, system 350, user 0Disk I/O: reads 0, writes 0Console I/O: reads 0, writes 0Paging: faults 0Network I/O: packets received 0, sent 0Cleaning up...root@yangyu-ubuntu-32:/mnt/nachos-3.4-Lab/nachos-3.4/threads# Challenge 线程调度算法扩展（至少实现一种算法）可实现“时间片轮转算法”、“多级队列反馈调度算法”，或将Linux或Windows采用的调度算法应用到Nachos上。 思路：nachos启动时在system.cc中会new一个timer类，每隔一个TimerTicks大小触发时钟中断，从而让时钟向前走，时间片的大下定义在stats.h中。同时在stats.h中定义一个时间片大小变量TimerSlice，每个线程运行时间只要大于等于TimerSlice，立即放弃CPU。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135stats.h：……// nachos执行每条用户指令的时间为1Tick#define UserTick 1// 系统态无法进行指令计算，// 所以nachos系统态的一次中断调用或其他需要进行时间计算的单位设置为10Tick#define SystemTick 10// 磁头寻找超过一个扇区的时间#define RotationTime 500// 磁头寻找超过一个磁道的时间#define SeekTime 500#define ConsoleTime 100 // time to read or write one character#define NetworkTime 100 // time to send or receive one packet// 时钟中断间隔#define TimerTicks 5 // (average) time between timer interrupts// 时间片轮转算法一个时间片大小#define TimerSlice 10 ……threadtest.cc:void SimpleThread(int which)&#123; for (int num = 0; num &lt; 5; num++) &#123; int ticks = stats-&gt;systemTicks - scheduler-&gt;getLastSwitchTick(); printf("userId=%d,threadId=%d,prio=%d,loop:%d,lastSwitchTick=%d,systemTicks=%d,usedTicks=%d,TimerSlice=%d\n",currentThread-&gt;getUserId(),currentThread-&gt;getThreadId(),currentThread-&gt;getPriority(),num,scheduler-&gt;getLastSwitchTick(),stats-&gt;systemTicks,ticks,TimerSlice); // 时间片轮转算法，判断时间片是否用完 // 如果用完主动让出cpu，针对nachos内核线程算法 if(ticks &gt;= TimerSlice)&#123; printf("threadId=%d Yield\n",currentThread-&gt;getThreadId()); currentThread-&gt;Yield(); &#125; // 非抢占模式下，多个线程同时执行该接口的话，会交替执行，交替让出cpu // currentThread-&gt;Yield(); &#125;&#125;threadtest.cc:// 创建四个线程，加上主线程共五个，时间片轮转调度策略，不可抢占void ThreadPriorityTest()&#123; Thread* t1 = new Thread("forkThread1", 1); printf("--&gt;name=%s,threadId=%d\n",t1-&gt;getName(),t1-&gt;getThreadId()); t1-&gt;Fork(SimpleThread, (void*)1); Thread* t2 = new Thread("forkThread2", 2); printf("--&gt;name=%s,threadId=%d\n",t2-&gt;getName(),t2-&gt;getThreadId()); t2-&gt;Fork(SimpleThread, (void*)2); Thread* t3 = new Thread("forkThread3", 3); printf("--&gt;name=%s,threadId=%d\n",t3-&gt;getName(),t3-&gt;getThreadId()); t3-&gt;Fork(SimpleThread, (void*)3); Thread* t4 = new Thread("forkThread4", 4); printf("--&gt;name=%s,threadId=%d\n",t4-&gt;getName(),t4-&gt;getThreadId()); t4-&gt;Fork(SimpleThread, (void*)4); currentThread-&gt;Yield(); SimpleThread(0);&#125;// 运行结果，可看到userTicks &gt;= TimserSlice时都让出cpu// 并且线程执行顺序为1 2 3 4 0，直到结束root@yangyu-ubuntu-32:/mnt/nachos-3.4-Lab/nachos-3.4/threads# root@yangyu-ubuntu-32:/mnt/nachos-3.4-Lab/nachos-3.4/threads# ./nachos -q 3--&gt;name=forkThread1,threadId=1--&gt;name=forkThread2,threadId=2--&gt;name=forkThread3,threadId=3--&gt;name=forkThread4,threadId=4userId=0,threadId=1,prio=1,loop:0,lastSwitchTick=50,systemTicks=60,usedTicks=10,TimerSlice=10threadId=1 YielduserId=0,threadId=2,prio=2,loop:0,lastSwitchTick=60,systemTicks=70,usedTicks=10,TimerSlice=10threadId=2 YielduserId=0,threadId=3,prio=3,loop:0,lastSwitchTick=70,systemTicks=80,usedTicks=10,TimerSlice=10threadId=3 YielduserId=0,threadId=4,prio=4,loop:0,lastSwitchTick=80,systemTicks=90,usedTicks=10,TimerSlice=10threadId=4 YielduserId=0,threadId=0,prio=6,loop:0,lastSwitchTick=90,systemTicks=100,usedTicks=10,TimerSlice=10threadId=0 YielduserId=0,threadId=1,prio=1,loop:1,lastSwitchTick=100,systemTicks=110,usedTicks=10,TimerSlice=10threadId=1 YielduserId=0,threadId=2,prio=2,loop:1,lastSwitchTick=110,systemTicks=120,usedTicks=10,TimerSlice=10threadId=2 YielduserId=0,threadId=3,prio=3,loop:1,lastSwitchTick=120,systemTicks=130,usedTicks=10,TimerSlice=10threadId=3 YielduserId=0,threadId=4,prio=4,loop:1,lastSwitchTick=130,systemTicks=140,usedTicks=10,TimerSlice=10threadId=4 YielduserId=0,threadId=0,prio=6,loop:1,lastSwitchTick=140,systemTicks=150,usedTicks=10,TimerSlice=10threadId=0 YielduserId=0,threadId=1,prio=1,loop:2,lastSwitchTick=150,systemTicks=160,usedTicks=10,TimerSlice=10threadId=1 YielduserId=0,threadId=2,prio=2,loop:2,lastSwitchTick=160,systemTicks=170,usedTicks=10,TimerSlice=10threadId=2 YielduserId=0,threadId=3,prio=3,loop:2,lastSwitchTick=170,systemTicks=180,usedTicks=10,TimerSlice=10threadId=3 YielduserId=0,threadId=4,prio=4,loop:2,lastSwitchTick=180,systemTicks=190,usedTicks=10,TimerSlice=10threadId=4 YielduserId=0,threadId=0,prio=6,loop:2,lastSwitchTick=190,systemTicks=200,usedTicks=10,TimerSlice=10threadId=0 YielduserId=0,threadId=1,prio=1,loop:3,lastSwitchTick=200,systemTicks=210,usedTicks=10,TimerSlice=10threadId=1 YielduserId=0,threadId=2,prio=2,loop:3,lastSwitchTick=210,systemTicks=220,usedTicks=10,TimerSlice=10threadId=2 YielduserId=0,threadId=3,prio=3,loop:3,lastSwitchTick=220,systemTicks=230,usedTicks=10,TimerSlice=10threadId=3 YielduserId=0,threadId=4,prio=4,loop:3,lastSwitchTick=230,systemTicks=240,usedTicks=10,TimerSlice=10threadId=4 YielduserId=0,threadId=0,prio=6,loop:3,lastSwitchTick=240,systemTicks=250,usedTicks=10,TimerSlice=10threadId=0 YielduserId=0,threadId=1,prio=1,loop:4,lastSwitchTick=250,systemTicks=260,usedTicks=10,TimerSlice=10threadId=1 YielduserId=0,threadId=2,prio=2,loop:4,lastSwitchTick=260,systemTicks=270,usedTicks=10,TimerSlice=10threadId=2 YielduserId=0,threadId=3,prio=3,loop:4,lastSwitchTick=270,systemTicks=280,usedTicks=10,TimerSlice=10threadId=3 YielduserId=0,threadId=4,prio=4,loop:4,lastSwitchTick=280,systemTicks=290,usedTicks=10,TimerSlice=10threadId=4 YielduserId=0,threadId=0,prio=6,loop:4,lastSwitchTick=290,systemTicks=300,usedTicks=10,TimerSlice=10threadId=0 YieldNo threads ready or runnable, and no pending interrupts.Assuming the program completed.Machine halting!Ticks: total 350, idle 0, system 350, user 0Disk I/O: reads 0, writes 0Console I/O: reads 0, writes 0Paging: faults 0Network I/O: packets received 0, sent 0Cleaning up...root@yangyu-ubuntu-32:/mnt/nachos-3.4-Lab/nachos-3.4/threads# 内容三：遇到的困难以及解决方法困难1切换线程过程中，产生段错误，通过定位，误把销毁的线程挂入就绪对了所致。 内容四：收获及感想自己动手实现后，发现时间片轮转算法，线程调度，FIFO，时钟中断等其实并不陌生。一切只要你不懒和肯付出实际行动的难题都是纸老虎。 内容五：对课程的意见和建议暂无。 内容六：参考文献暂无。]]></content>
      <categories>
        <category>线程调度算法</category>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>Nachos-3.4</tag>
        <tag>时间片轮转调度策略</tag>
        <tag>FIFO线程调度策略</tag>
        <tag>基于优先级的可抢占式调度策略</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nachos-Lab1-完善线程机制]]></title>
    <url>%2F2019%2F05%2F13%2Fnachos-3-4-Lab1%2F</url>
    <content type="text"><![CDATA[Nachos是什么Nachos (Not Another Completely Heuristic Operating System)，是一个教学用操作系统，提供了操作系统框架： 线程 中断 虚拟内存（位图管理所有物理页，虚拟地址与物理地址之间的转换等） 同步与互斥机制（锁、条件变量、信号量），读者写者问题，生产者消费者问题，BARRIER问题等 线程调度（基于优先级可抢占式调度，时间片轮转算法，FIFO调度） 文件系统 系统调用 机器指令、汇编指令、寄存器……Nachos模拟了一个MIPS模拟器，运行用户程序。 目录结构12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576.├── COPYRIGHT├── gnu-decstation-ultrix // 交叉编译工具链├── nachos-3.4.zip // 未经任何修改的源码和交叉编译工具，实验就是修改源码完善各个模块的功能├── README└── nachos-3.4 // 实验过程中完善的代码 ├── test // 该目录下编写用户自己的程序，需要修改Makfile添加自己的文件 ├── bin // 用户自己的程序需要利用coff2noff转换，才能在nachos下跑起来 ├── filesys // 文件系统管理 │ ├── directory.cc // 目录文件，由目录项组成，目录项里记录了文件头所在扇区号 │ ├── directory.h │ ├── filehdr.cc │ ├── filehdr.h // 文件头数据结构，通过索引记录了文件内容实际存储的所有扇区号 │ ├── filesys.cc // 文件系统数据结构，创建/删除/读/写/修改/重命名/打开/关别等接口 │ ├── filesys.h │ ├── fstest.cc │ ├── Makefile │ ├── openfile.cc // 管理所有打开的文件句柄 │ ├── openfile.h │ ├── synchdisk.cc // 同步磁盘类，加锁保证互斥和文件系统的一致性 │ ├── synchdisk.h │ └── test ├── machine // 机器硬件模拟 │ ├── console.cc // 终端 │ ├── console.h │ ├── disk.cc // 磁盘 │ ├── disk.h │ ├── interrupt.cc // 中断处理器，利用FIFO维护一个中断队列 │ ├── interrupt.h │ ├── timer.cc // 模拟硬件时钟，用于时钟中断 │ ├── timer.h │ ├── translate.cc // 用户程序空间虚拟地址和物理之间的转换类 │ └── translate.h ├── network // 网络系统管理 │ ├── Makefile │ ├── nettest.cc │ ├── post.cc │ ├── post.h │ └── README ├── threads // 内核线程管理 │ ├── list.cc // 工具模块 定义了链表结构及其操作 │ ├── list.h │ ├── main.cc // main入口，可以传入argv参数 │ ├── Makefile │ ├── scheduler.cc // 调度器，维护一个就绪的线程队列，时间片轮转/FIFO/优先级抢占 │ ├── scheduler.h │ ├── stdarg.h │ ├── switch.c // 线程启动和调度模块 │ ├── switch.h │ ├── switch-old.s │ ├── switch.s // 线程切换 │ ├── synch.cc // 同步与互斥，锁/信号量/条件变量 │ ├── synch.dis │ ├── synch.h │ ├── synchlist.cc // 类似于一个消息队列 │ ├── synchlist.h │ ├── system.cc // 主控模块 │ ├── system.h │ ├── thread.cc // 线程数据结构 │ ├── thread.h │ ├── threadtest.cc │ ├── utility.cc │ └── utility.h ├── userprog // 用户进程管理 │ ├── addrspace.cc // 为noff文件的代码段/数据段分配空间，虚拟地址空间 │ ├── addrspace.h │ ├── bitmap.cc // 位图，用于管理扇区的分配和物理地址的分配 │ ├── bitmap.h │ ├── exception.cc // 异常处理 │ ├── Makefile │ ├── progtest.cc // 测试nachos是否可执行用户程序 │ └── syscall.h // 系统调用 └── vm // 虚拟内存管理 └── Makefile // 多线程编译: make -j4 └── Makefile.common // 各个模块公共的Makefile内容存放到这里面 └── Makefile.dep // 依赖 环境选择Linux或Unix系统，安装32位GCC开发环境，安装32的ubuntu。 源码获取https://github.com/icoty/nachos-3.4-Lab 内容一：总体概述本次Lab针对的内容是实现线程机制最基本的数据结构——进程控制块（PCB）。当一个进程创建时必然会生成一个相应的进程控制块，记录一些该线程特征，如进程ID、进程状态、进程优先级，进程开始运行时间，在cpu上已经运行了多少时间，程序计数器，SP指针，根目录和当前目录指针，文件描述符表，用户ID，组ID，指向代码段、数据段和栈段的指针等（当然，Nachos简化了进程控制块的内容）。实验的主要内容是修改和扩充PCB，主要难点在于发现修改PCB影响到的文件并进行修改。PCB是系统感知进程存在的唯一标志，且进程与PCB一一对应。可将PCB内部信息划分为：进程描述信息，进程控制信息，进程占有的资源和使用情况，进程的cpu现场。扩展字段如下： 内容二：任务完成情况任务完成列表（Y/N） Exercise1 Exercise2 Exercise3 Exercise4 第一部分 Y Y Y Y 具体Exercise的完成情况Exercise1 调研调研Linux或Windows中进程控制块（PCB）的基本实现方式，理解与Nachos的异同。 linux-4.19.23调研：Linux中的每一个进程由一个task_struct数据结构来描述。task_struct也就是PCB的数据结构。task_struct容纳了一个进程的所有信息，linux内核代码中的task_struct在linux-4.19.23/include/linux/sched.h内。 Linux内核进程状态：如下可分为运行态，可中断和不可中断态，暂停态，终止态，僵死状态，挂起状态等。 Linux内核进程调度：sched_info数据结构，包括被调度次数，等待时间，最后一次调度时间。vi linux-4.19.23/include/linux/sched.h：123456789101112131415161718192021222324252627282930313233343536373839404142……/* Used in tsk-&gt;state: */#define TASK_RUNNING 0x0000 // 运行态#define TASK_INTERRUPTIBLE 0x0001 // 可中断#define TASK_UNINTERRUPTIBLE 0x0002 // 不可中断#define __TASK_STOPPED 0x0004 #define __TASK_TRACED 0x0008/* Used in tsk-&gt;exit_state: */#define EXIT_DEAD 0x0010#define EXIT_ZOMBIE 0x0020 // 僵死态#define EXIT_TRACE (EXIT_ZOMBIE | EXIT_DEAD)/* Used in tsk-&gt;state again: */#define TASK_PARKED 0x0040#define TASK_DEAD 0x0080#define TASK_WAKEKILL 0x0100#define TASK_WAKING 0x0200#define TASK_NOLOAD 0x0400#define TASK_NEW 0x0800#define TASK_STATE_MAX 0x1000…………struct sched_info &#123;#ifdef CONFIG_SCHED_INFO /* Cumulative counters: */ /* # of times we have run on this CPU: */ unsigned long pcount; /* Time spent waiting on a runqueue: */ unsigned long long run_delay; /* Timestamps: */ /* When did we last run on a CPU? */ unsigned long long last_arrival; /* When were we last queued to run? */ unsigned long long last_queued;#endif /* CONFIG_SCHED_INFO */&#125;;…… 时钟与锁：内核需要记录进程在其生存期内使用CPU的时间以便于统计、计费等有关操作。进程耗费CPU的时间由两部分组成：一是在用户态下耗费的时间，一是在系统态下耗费的时间。这类信息还包括进程剩余的时间片和定时器信息等，以控制相应事件的触发。 文件系统信息：进程可以打开或关闭文件，文件属于系统资源，Linux内核要对进程使用文件的情况进行记录。 虚拟内存信息：除了内核线程，每个进程都拥有自己的地址空间，Linux内核中用mm_struct结构来描述。 物理页管理信息：当物理内存不足时，Linux内存管理子系统需要把内存中部分页面交换到外存，并将产生PageFault的地址所在的页面调入内存，交换以页为单位。这部分结构记录了交换所用到的信息。 多处理器信息：与多处理器相关的几个域，每个处理器都维护了自己的一个进程调度队列，Linux内核中没有线程的概念，统一视为进程。 处理器上下文信息：当进程因等待某种资源而被挂起或停止运行时，处理机的状态必须保存在进程的task_struct，目的就是保存进程的当前上下文。当进程被调度重新运行时再从进程的task_struct中把上下文信息读入CPU（实际是恢复这些寄存器和堆栈的值），然后开始执行。 与Nachos的异同：Nachos相对于Linux系统的线程部分来讲，要简单许多。它的PCB仅有几个必须的变量，并且定义了一些最基本的对线程操作的函数。Nachos线程的总数目没有限制，线程的调度比较简单，而且没有实现线程的父子关系。很多地方需要完善。 Exercise2 源代码阅读code/threads/main.cc：main.cc是整个nachos操作系统启动的入口，通过它可以直接调用操作系统的方法。通过程序中的main函数，配以不同的参数，可以调用Nachos操作系统不同部分的各个方法。 code/threads/threadtest.cc：nachos内核线程测试部分，Fork两个线程，交替调用Yield()主动放弃CPU，执行循环体，会发现线程0和线程1刚好是交替执行。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566int main(int argc, char **argv)&#123; int argCount; // the number of arguments DEBUG('t', "Entering main"); (void) Initialize(argc, argv);#ifdef THREADS for (argc--, argv++; argc &gt; 0; argc -= argCount, argv += argCount) &#123; argCount = 1; switch (argv[0][1]) &#123; case 'q': testnum = atoi(argv[1]); argCount++; break; case 'T': if(argv[0][2] == 'S') testnum = 3; break; default: testnum = 1; break; &#125; &#125; ThreadTest();#endif ……&#125;threadtest.cc// 线程主动让出cpu,在FIFO调度策略下能够看到多个线程按顺序运行void SimpleThread(int which)&#123; for (int num = 0; num &lt; 5; num++) &#123; int ticks = stats-&gt;systemTicks - scheduler-&gt;getLastSwitchTick(); // 针对nachos内核线程的时间片轮转算法，判断时间片是否用完，如果用完主动让出cpu if(ticks &gt;= TimerSlice)&#123; currentThread-&gt;Yield(); &#125; // 多个线程同时执行该接口的话，会交替执行，交替让出cpu // currentThread-&gt;Yield(); &#125;&#125;root@yangyu-ubuntu-32:/mnt/nachos-3.4/code/threads# root@yangyu-ubuntu-32:/mnt/nachos-3.4/code/threads# ./nachos -q 1userId=0,threadId=0,prio=5,loop:0,lastSwitchTick=0,systemTicks=20,usedTicks=20,TimerSlice=30userId=0,threadId=1,prio=5,loop:0,lastSwitchTick=20,systemTicks=30,usedTicks=10,TimerSlice=30userId=0,threadId=0,prio=5,loop:1,lastSwitchTick=30,systemTicks=40,usedTicks=10,TimerSlice=30userId=0,threadId=1,prio=5,loop:1,lastSwitchTick=40,systemTicks=50,usedTicks=10,TimerSlice=30userId=0,threadId=0,prio=5,loop:2,lastSwitchTick=50,systemTicks=60,usedTicks=10,TimerSlice=30userId=0,threadId=1,prio=5,loop:2,lastSwitchTick=60,systemTicks=70,usedTicks=10,TimerSlice=30userId=0,threadId=0,prio=5,loop:3,lastSwitchTick=70,systemTicks=80,usedTicks=10,TimerSlice=30userId=0,threadId=1,prio=5,loop:3,lastSwitchTick=80,systemTicks=90,usedTicks=10,TimerSlice=30userId=0,threadId=0,prio=5,loop:4,lastSwitchTick=90,systemTicks=100,usedTicks=10,TimerSlice=30userId=0,threadId=1,prio=5,loop:4,lastSwitchTick=100,systemTicks=110,usedTicks=10,TimerSlice=30No threads ready or runnable, and no pending interrupts.Assuming the program completed.Machine halting!Ticks: total 130, idle 0, system 130, user 0Disk I/O: reads 0, writes 0Console I/O: reads 0, writes 0Paging: faults 0Network I/O: packets received 0, sent 0Cleaning up... code/threads/thread.h：这部分定义了管理Thread的数据结构，即Nachos中线程的上下文环境。主要包括当前线程栈顶指针，所有寄存器的状态，栈底，线程状态，线程名。当前栈指针和机器状态的定义必须必须放作为线程成员变量的前两个，因为Nachos执行线程切换时，会按照这个顺序找到线程的起始位置，然后操作线程上下文内存和寄存器。在Thread类中还声明了一些基本的方法，如Fork()、Yield()、Sleep()等等，由于这些方法的作用根据名字已经显而易见了，在此不再赘述。 code/threads/thread.cc： Thread.cc中主要是管理Thread的一些事务。主要接口如下： Fork(VoidFunctionPtr func,int arg)：func是新线程运行的函数，arg是func函数的入参，Fork的实现包括分为几步：分配一个堆栈，初始化堆栈，将线程放入就绪队列。 Finish()：不是直接收回线程的数据结构和堆栈，因为当前仍在这个堆栈上运行这个线程。先将threadToBeDestroyed的值设为当前线程，在Scheduler的Run()内切换到新的线程时在销毁threadToBeDestroyed。Yield()、Sleep()。这里实现的方法大多是都是原子操作，在方法的一开始保存中断层次关闭中断，并在最后恢复原状态。 Yield()：当前线程放入就绪队列，从scheduler就绪队列中的找到下一个线程上cpu，以达到放弃CPU的效果。 Exercise3 扩展线程的数据结构Exercise4 增加全局线程管理机制这里我把Exercise3和Exercise4放在一起完成。 在Thread类中添加私有成员userId和threadId，添加公有接口getUserId()和getThreadId()，userId直接沿用Linux个getuid()接口。 system.h内部添加全局变量maxThreadsCount=128，全局数组threads[maxThreadsCount]，每创建一个线程判断并分配threadId。 -TS模仿Linux的PS命令打印所有线程信息，仔细阅读list.cc代码和scheduler.cc的代码，就会发现可以直接用scheduler.cc::Print()接口，不用我们重新造轮子。 在system.cc中的void Initialize(int argc, char argv)函数体对全局数组初始化。如下我用root用户执行分配的userId为0，切换到其他用户userId会发生变化，线程id分别为0和1。当线程数超过128个线程时，ASSERT断言报错。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455threadtest.cc：void ThreadTest()&#123; switch (testnum) &#123; case 1: ThreadTest1(); break; case 2: ThreadCountLimitTest(); break; case 3: ThreadPriorityTest(); break; case 4: ThreadProducerConsumerTest(); break; case 5: ThreadProducerConsumerTest1(); break; case 6: barrierThreadTest(); break; case 7: readWriteThreadTest(); break; default: printf("No test specified.\n"); break; &#125;&#125;// 线程最多128个，超过128个终止运行void ThreadCountLimitTest()&#123; for (int i = 0; i &lt;= maxThreadsCount; ++i) &#123; Thread* t = new Thread("fork thread"); printf("thread name = %s, userId = %d, threadId = %d\n", t-&gt;getName(), t-&gt;getUserId(), t-&gt;getThreadId()); &#125;&#125;root@yangyu-ubuntu-32:/mnt/nachos-3.4/code/threads# ./nachos -TSthread name = fork thread, userId = 0, threadId = 1thread name = fork thread, userId = 0, threadId = 2thread name = fork thread, userId = 0, threadId = 3……thread name = fork thread, userId = 0, threadId = 122thread name = fork thread, userId = 0, threadId = 123thread name = fork thread, userId = 0, threadId = 124thread name = fork thread, userId = 0, threadId = 125thread name = fork thread, userId = 0, threadId = 126thread name = fork thread, userId = 0, threadId = 127allocatedThreadID fail, maxThreadsCount:[128]Assertion failed: line 73, file "../threads/thread.cc"Aborted (core dumped)root@yangyu-ubuntu-32:/mnt/nachos-3.4/code/threads# 内容三：遇到的困难以及解决方法困难1开始make编译出错，通过定位到具体行，复制出来手动执行，发现是gcc交叉编译工具链路径不对。 困难2刚开始修改代码验证效果，重定义错误，外部文件全局变量使用方式不对导致。 内容四：收获及感想动手实践很重要，不管你是做什么事、什么项目、什么作业，一定要落实到代码和跑到程序上面来。绝知此事要躬行，学习来不得半点虚假。 内容五：对课程的意见和建议暂无。 内容六：参考文献暂无。]]></content>
      <categories>
        <category>线程机制</category>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>Nachos-3.4</tag>
        <tag>PCB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[另类P、V操作问题-详细图解]]></title>
    <url>%2F2019%2F04%2F25%2Fstack-pv%2F</url>
    <content type="text"><![CDATA[问题模型有一个系统，定义如下P、V操作：123456789P(s)： s.count--; if s&lt;0 then 将本进程插入相应队列末尾等待; V(s): s.count++; if s&lt;=0 then 从相应等待队列队尾唤醒一个进程，将其插入就绪队列; 思考并回答:a. 这样定义P、V操作是否有问题?b. 试用这样的P、V操作实现N个进程竞争使用某一共享变量的互斥机制。c. 对于b的解法，有无效率更高的方法。如有，试问降低了多少复杂性? 分析a. 当然有问题，假设s=2，现有进程p1、p2按顺序来请求共享资源A，p1和p2直接获取A，假设p1和p2都还未释放A的时候，p3、p4、p5按顺序也来请求A，这时s的等待队列L为：(尾)p5p4p3(头)，然后p1释放A，执行V(s)操作从L队尾唤醒p5，L变为：(尾)p4p3(头)。这时A被p2和p5持有，且p2和p5都未释放A的时候，假设这时p1又来请求A，p1被挂起，L变为：(尾)p1p4p3(头)。然后p2释放A执行V(s)操作从L队尾唤醒p1，你会发现p1又竞争到了A，而p3和p4还一次都未竞争到，这会导致越靠近L队首的p3和p4越容易饿死，出现饥饿现象。问题的根源就在于这样定义的P、V操作，由于在信号量的等待队列上是先进后出导致的，这属于栈P、V。 b. 解决方案这里以N个进程为例进行一般化分析，定义信号量数组S[N-1]，共有N-1个信号量，下标从0～N-2，其中S[i] = N-i-1，表示第i+1个信号量S[i]的初值为N-i-1，初值为何取这个看后面分析，下为伪码。 123456789Semaphore S[N-1]; // S[i] = N-i-1void func()&#123; for(int i=0 ; i&lt;n-1 ; i++) P(S[i]); // 临界区 Critical Section for(int i=n-2 ; i&gt;=0 ; i--) V(S[i]);&#125; 一定要注意P(S[i])操作中的i是从0～N-2，而V(S[i])的i是反过来的从N-2～0，这个很重要，这个就是多级队列的精髓，顺序不能换。下面的分析，假设t1时刻p1进入临界区还没出来之前，t2～tN时刻p2～pN按顺序来请求进入临界区，那么p2～pN都执行for循环，分别被挂起在信号量N-2～0的等待队列上，并且每个信号量的等待队列上有且只有一个进程被挂起。在tN+1时刻p1出临界区，由于V(S[i])是从N-2～0，因此等待在LN-2上的P2最先被唤醒，然后L2进入临界区。之后按顺序p3～pN依次被唤醒并依次挂入就绪队列等待被调度，而处理器从就绪队列进行调度是FIFO，与请求临界区的顺序一致，饥饿现象得以解决。 该方法的资源复杂度为O(N-1)，需要N-1个信号量。 c. 优化方法除了前面的办法，已经可以确定存在更优方案能把资源复杂度降为O(logN)，具体怎么做，后期揭晓。]]></content>
      <categories>
        <category>同步机制</category>
        <category>互斥机制</category>
      </categories>
      <tags>
        <tag>信号量Semaphore</tag>
        <tag>临界区</tag>
        <tag>P/V操作</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker最简教程]]></title>
    <url>%2F2019%2F04%2F22%2Fdocker%2F</url>
    <content type="text"><![CDATA[本文旨在让你用最短的时间弄懂Docker命令操作，什么虚拟化都太泛泛了，不讲大道理，实践出真知，让你从此的日常开发和工作中在面对Docker时不再茫然失措而是得心应手。本文也不谈安装，我实在认为作为程序员，要是我在这里教你如何安装Docker，既是在浪费你的时间也是在浪费我的时间，请参考Docker安装； Docker Hub是Docker官方维护的一个公共仓库，其中已经包括了数量超过15 000 的镜像，开发者可以注册自己的账号，并自定义自己的镜像进行存储，需要的时候可以直接拿来用，同时也能够分享，有点类似于Github，如想注册可移步 Docker Hub，注册与否不影响接下来的操作。 实践出真知我认为只要你不是专门研究这个的，那么你只需学会如何使用Docker的一些基本命令，使自己的日常开发和工作不受阻碍，弄清Docker和容器之间的区别，为什么现在很多企业流行Docker，这个东西解决了啥问题，有啥优势就够了。关于Docker是什么有何优势，这里挑了一个简洁的博客链接。 接下来从零开始，首先从docker hub仓库上拉取centos镜像，带你走进docker日常命令，学会这些命令，足以应对你的日常开发和工作中关于docker的问题。 search: 从docker hub仓库搜索带centos的所有镜像。1$docker seach centos images: 查看本地所有镜像，pull前左侧REPOSITORY栏无centos。REPOSITORY表示镜像被归入到本地的仓库，比如icoty1/lamp:v1.0.0表示本地icoty1仓库下有一个镜像名为lamp,其TAG(版本)为v1.0.0，每个镜像有一个IMAGE ID唯一标识该镜像，SIZE为镜像大小。1$docker images pull: 从docker hub远程仓库把centos镜像拉到本地，pull后再次执行images，会发现centos已经被拉到本地。1$docker pull centos ps: 只列出正在运行的容器。1$docker ps ps -a: 列出所有容器, 每一个容器有一个CONTAINER ID唯一标识该容器；IMAGE表示该容器是基于哪个镜像生成的，COMMAND是容器启动时执行的命令，可以传入也可以不传入；STATUS是容器当前的状态，Exit是已停止，Up是正在运行。1$docker ps -a run: 从镜像衍生一个新的容器并运行；-d后台模式运行容器，-i交互模式运行容器；-p把主机80关口映射到容器的80端口，因为容器具有封闭性，容器外部不能直接访问容器内部的端口，通过映射后，主机80端口收到数据后会转发到容器内部的80端口，不过在容器内是可以直接访问容器外的主机的；-v把主机的/Users/yangyu/ide/LeetCode/目录映射到容器的/LeetCode/，容器内若无/LeetCode/目录会自动创建，用于实现主机和容器之间的目录共享，在两个目录下操作文件是对等的；centos:latest是镜像名称，可以换成IMAGE ID，二者等价；/bin/bash是容器启动时执行的命令，还可以带参数，这个不懂的可以搜索下。执行docker run后再次执行ps命令，能够看到运行中的容器多了一个。1$docker run -d -ti -p 80:80 -v /Users/yangyu/ide/LeetCode/:/LeetCode/ centos:latest /bin/bash cp: 拷贝主机/Users/yangyu/ide/LeetCode/Database/目录到容器eaf43b370eb7根目录。1$docker cp /Users/yangyu/ide/LeetCode/Database/ eaf43b370eb7:/ exec: 执行该命令进入容器eaf43b370eb7内，进入容器后在容器内/LeetCode/目录下新建readme.py2，在主机/Users/yangyu/ide/LeetCode/目录下能够看到该文件。12$docker exec -it eaf43b370eb7 /bin/bash$cp /LeetCode/readme.py /LeetCode/readme.py2 cp: 从容器eaf43b370eb7根目录下拷贝目录/Database到主机的/Users/yangyu/ide/LeetCode/Database/目录下。1$docker cp eaf43b370eb7:/Database/ /Users/yangyu/ide/LeetCode/Database/ stop/restart: 停止容器eaf43b370eb7然后查看其状态变为Exited；然后通过restart命令重启，容器又处于运行态。12$docker stop eaf43b370eb7$docker restart eaf43b370eb7 tag: 把centos镜像归入icoty1仓库下名称为centos，TAG为7，TAG随你定。1$docker tag centos icoty1/centos:7 commit: 最初pull下来的centos镜像是最简版本，里面没有安装mysql vim等；最初pull下来后基于其运行一个容器，你在容器内部可以安装你需要的环境，比如mysql，apache，nginx，hexo博客等，安装好后通过commit命令把容器提交为一个新的镜像，以后凡是从这个新的镜像运行的容器都带有你安装的内容。-m是提交说明；-p是执行commit命令时暂停该容器；eaf43b370eb7是容器ID。1$docker commit -m "提交我的自定义镜像，centos7内安装mysql，版本号v1.0.0" -p eaf43b370eb7 icoty1/centos7-mysql:v1.0.0 save: 把镜像03cb190015bf打包成主机目录/Users/yangyu/ide/LeetCode/下的centos7-mysql.tar，然后你可以通过U盘拷贝到其他机器上，在其他机器上通过load命令可以把centos7-mysql.tar加载成一个镜像。1$docker save 03cb190015bf &gt; /Users/yangyu/ide/LeetCode/centos7-mysql.tar load: 把centos7-mysql.tar加载为镜像，因为这个包是从我主机上的镜像03cb190015bf打出来的，所以执行load的时候直接返回镜像03cb190015bf，如果在其他机器上执行会生成一个新的镜像ID。1$docker load &lt; /Users/yangyu/ide/LeetCode/centos7-mysql.tar push: 把本地icoty1仓库下TAG为v1.0.0的镜像icoty1/centos7-mysql推到远程仓库docker hub上的icoty1仓库下保存，执行push前需要在本地icoty1已经登陆。push成功之后，其他人就可以通过pull命令拉取你的镜像使用了，相当于git clone操作。12$docker push icoty1/centos7-mysql:v1.0.0$docker pull icoty1/centos7-mysql:v1.0.0 rm: 删除容器eaf43b370eb7，运行中的容器无法删除。1$docker rm eaf43b370eb7 rmi: 删除镜像03cb190015bf，在这之前必须删除由该镜像衍生出来的所有容器删除，否则会删除失败，执行该命令后通过images发现镜像已经没有了。1$docker rmi 03cb190015bf build: 如下以我搭建hexo博客的Dockerfile举例说明。12345678910111213141516171819202122232425# 基础镜像，icoty1/ubuntu-hexo-blog:latest在本地仓库必须已经存在FROM icoty1/ubuntu-hexo-blog:latest# 维护人员信息，可写可不写MAINTAINER icoty1 "https://icoty.github.io" # 暴露容器的4000端口，这样主机就可以映射端口到4000了EXPOSE 4000/*自动安装所需环境，可替换成安装mysql vim等你需要的命令 *hexo部分插件安装，使支持rss，图片，字数统计等功能 */RUN npm install -g hexo-cli \&amp;&amp; npm install hexo-server --save \&amp;&amp; hexo init blog &amp;&amp; cd /blog \&amp;&amp; npm install \&amp;&amp; npm install hexo-deployer-git --save \&amp;&amp; npm install hexo-migrator-rss --save \ &amp;&amp; npm install hexo-asset-image --save \&amp;&amp; npm install hexo-wordcount --save \&amp;&amp; npm install hexo-generator-sitemap --save \ &amp;&amp; npm install hexo-generator-baidu-sitemap --save \ &amp;&amp; npm install hexo-helper-live2d --save \&amp;&amp; git clone https://github.com/litten/hexo-theme-yilia.git themes/yilia \&amp;&amp; sed "s/theme: landscape/theme: yilia/g" -i /blog/_config.yml 12$ docker build -t icoty1/ubuntu-hexo . # icoty1/ubuntu-hexo是新的镜像的名字$ docker images # build后会多出icoty1/ubuntu-hexo镜像 镜像与容器为了便于理解，你可以把镜像理解成一个初始模版A，通过这个模板A你可以复制出模板B、模板C等，模板B和模板C在这里就相当于容器，突然某一天你发现模板A现有的内容已经不能满足你的需求了（比如模板A没有安装Mysql，而你需要安装Mysql），这时你就只能自定义新的模板(相当于自定义新的符合你的要求的镜像)，而自定义方式则可以从模板B或模板C中安装Mysql，安装成功之后，通过docker commit命令将模板B或模板C提交成一个新的初始模板A1（也就是新的镜像），以后所有从模板A1运行的容器就都有Mysql了，然后你就有模板A和模板A1了（就是两个镜像）。 建议实际操作部分，对各个命令有疑问的，相信我，直接执行一遍才是解决你心中疑虑的不二之法，如果你的命令参数不正确，顶多就是报错和执行不成功，不会让你的主机崩溃，最坏也就不过重新执行一遍，IT这个职业，其本身就是一个不断试错、犯错和总结经验的过程，如果你学到了，请我喝奶茶吧，小生会一直奋斗在原创的路上。 参考文献Docker命令Docker中文社区]]></content>
      <categories>
        <category>Docker教程</category>
      </categories>
      <tags>
        <tag>Dockerfile</tag>
        <tag>镜像</tag>
        <tag>容器</tag>
        <tag>Docker教程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo+Github博客最简教程-Dockerfile自动搭建]]></title>
    <url>%2F2019%2F04%2F18%2Fdocker-hexo-blog%2F</url>
    <content type="text"><![CDATA[闲谈拿出你的气质，打开你的电脑，借你半小时搭建好属于你的hexo博客，小生用dockerfile自动帮你搭建好；你只需要在你的mac或linux或windows上提前把docker安装好，如何安装不是我的重点，请参考Docker安装；作为程序员，博客就像你的影子，我都已经忘了内心曾经多少次告诫自己，一定要搭建一个属于自己的技术博客，奈何日复一日过去了，近来终于落实到行动上来，所谓明日复明日，明日何其多，早晚要做的事，劝君晚做不如早做。 搭建Hexo获取基础镜像Docker安装成功之后方能进行接下来的操作，如果对Docker基本命令不熟悉又想真懂的可以看下我的另一篇文章Docker最简教程。首先从我的Docker Hub仓库上获取基础镜像： 12$ docker pull icoty1/ubuntu-hexo-blog # 从Docker hub上的icoty1用户下获取基础镜像$ docker images # 查看本地所有镜像，会发现icoty1/ubuntu-hexo-blog已经被pull下来了 生成Dockerfile进入一个空的目录下新建空文件Dockerfile，复制如下内容： 123456789101112131415161718192021# 基础镜像FROM icoty1/ubuntu-hexo-blog:latestMAINTAINER icoty1 "https://icoty.github.io" EXPOSE 4000# hexo部分插件安装，使支持rss，图片，字数统计等功能RUN npm install -g hexo-cli \&amp;&amp; npm install hexo-server --save \&amp;&amp; hexo init blog &amp;&amp; cd /blog \&amp;&amp; npm install \&amp;&amp; npm install hexo-deployer-git --save \&amp;&amp; npm install hexo-migrator-rss --save \&amp;&amp; npm install hexo-asset-image --save \&amp;&amp; npm install hexo-wordcount --save \&amp;&amp; npm install hexo-generator-sitemap --save \&amp;&amp; npm install hexo-generator-baidu-sitemap --save \&amp;&amp; npm install hexo-helper-live2d --save \&amp;&amp; git clone https://github.com/litten/hexo-theme-yilia.git themes/yilia \&amp;&amp; sed "s/theme: landscape/theme: yilia/g" -i /blog/_config.yml 更换主题Dockerfile中的最后两行内容表示的含义是从github上把hexo-theme-yilia克隆下来并重命名成yilia，然后放到容器的/blog/themes/目录下，其中hexo-theme-yilia是hexo的主题，hexo有很多种主题，用每一种主题搭建出来的hexo博客界面美观和布局都不尽相同，你可以通过hexo官网上浏览每一种主题长啥样子，通过github获取主题的源码仓库，选择一个你喜欢的主题，并相应的修改这两行。假如你从github选择的主题仓库地址是https://github.com/yscoder/hexo-theme-indigo.git ， 那么你需要按照如下方式进行修改，如果你就想用yilia，那么你不需要做任何修改，我用的主题是https://github.com/theme-next/hexo-theme-next.git 12&amp;&amp; git clone https://github.com/yscoder/hexo-theme-indigo.git themes/indigo \&amp;&amp; sed "s/theme: landscape/theme: indigo/g" -i /blog/_config.yml 构建Hexo镜像在Dockerfile的同级目录执行： 12$ docker build -t icoty1/ubuntu-hexo . # 把icoty1/ubuntu-hexo替换成你取的名字$ docker images # 能够看到多出一条记录icoty1/ubuntu-hexo，并能看到该镜像的[IMAGE ID] 启动容器123456789/* 把[IMAGE ID]替换成上一步构建出来的镜像的ID，该句执行成功会多出来一个容器并有一个[CONTAINER ID] * -v /home/yangyu/blog/：/blog/是把本机的/home/yangyu/blog/目录映射到容器的/blog/目录 * 通过目录映射，你只需要在本机编辑/home/yangyu/blog/目录下的文件，而不用每次都进入容器/blog/目录下编辑文件 * -p 4000:4000 将主机的4000端口映射到容器的4000端口 *\$ docker run -d -ti -p 4000:4000 -v /home/yangyu/blog/：/blog/ [IMAGE ID] /bin/bash $ docker ps -a # 执行该句列出当前所有的容器$ docker exec -it [CONTAINER ID] /bin/bash # 根据前一步的容器ID进入该容器内部$ cd /blog/ &amp;&amp; hexo s # 进入容器内部的/blog/目录下，启动hexo 浏览器测试浏览器访问http://localhost:4000 ，出现下图说明已经成功，以后你的博客配置，文章撰写和发布等，都在/home/yangyu/blog/目录下进行，这和在容器内部/blog/目录下操作完全对等。 Hexo部署到Github注册Github账户，如果已经注册，跳过此步；在github上仓库“用户名.github.io”，比如我的用户名为icoty，仓库名则为：icoty.github.io； 执行如下命令生成ssh key，执行完后复制~/.sshid_rsa.pub文件内的全部内容，按照图示添加ssh keys，并粘贴保存到Key栏中，Title栏随便取。 1234$ cd ~/.ssh$ ssh-keygen -t rsa -C "youremail@example.com" # 全程回车$ git config --global user.name "你用github用户名"$ git config --global user.email "你的github邮箱地址" 配置Hexo主题编辑/blog/_config.yml文件，编辑标题、描述信息、Github信息，下图参见我的： 1234567891011121314# Sitetitle: 阳光沥肩头 仿佛自由人 # 标题subtitle: # 子标题description: Linux C++服务端 # 描述信息keywords: author: icotylanguage: zh-CN # 语言timezone: # 时区deploy: - type: git repository: git@github.com:icoty/icoty.github.io.git # 设置repository对应的链接 branch: master # 设置提交到的分支 message: Site updated at &#123;&#123; now("YYYY-MM-DD HH:mm:ss") &#125;&#125; # 设置我们提交的信息 执行如下命令发布到github上，通过“https://你的github用户名.github.io”访问，我的是https://icoty.github.io 12$hexo generate$hexo deploy # 部署到GitHub 编辑/blog/themes/yilia/_config.yml文件，自定义其他配置，如友链、评论、分享、头像等，这些配置并不是一定要做，做不做都行，只是配置的完善些，你的Hexo博客界面看起来美观些，如何配置在此不一一赘述，请自行查看对应主题的官方文档和Github说明。如果你能操作这里，说明我这个教程还是有效的，感谢你的坚持！ Hexo命令Hexo搭建好后，你可以写博客发布到GitHub 上，别人通过“https://你的github用户名.github.io”就能访问你的博客和看到你写的文章，而这个章节就是教你怎么在本地写你的博客，写博客用的MarkDown语法，推荐你安装MarkDown编辑器Typora。下面列出写博客过程中常用的命令，这些命令都需要走到/blog/目录下执行。 123456789$hexo new "my-hexo" #新建my-hexo文章，在/blog/source/_post/目录下生成my-hexo.md，在这个文件里面写你的文章$hexo generate # 文章写好后保存，然后执行这条命令，生成静态页面至public目录$hexo s # 然后开启预览访问端口（默认端口4000，'ctrl+c'关闭server，‘ctrl+z’放到后台运行），通过http://localhost:4000 查看效果，如果满意就执行下一条命令发布到github$hexo deploy # 发布到github，通过https://你用github用户名.github.io 访问$hexo clean # 有时你写文章和配置其他内容后，老是不生效，就执行下该命令清除缓存文件 (db.json) 和已生成的静态文件 (public)，不是删除，你的文章仍然在的$nohup hexo s &amp; # 启动hexo以后台方式运行$hexo new page "About" #新建About页面，这个是配置Hexo界面多出来一个About布局$hexo help # 查看帮助$hexo version #查看Hexo的版本 MarkDown语法这个比较基础，网上教程也一大堆，MarkDown很容易学，放心比九九表容易多了，只要你用markdown实际动手写过一篇博文后就上手了，因此没啥可说的。 Next主题配置接下来的内容是针对next主题的配置，因为我选择的是next，不同主题可能有差异，特此说明。 修改文章内链接文本样式打开themes/next/source/css/_common/components/post/post.styl文件，在文件最后且在@import之前添加如下代码：1234567891011// 文章内链接文本样式.post-body p a&#123; color: #0593d3; //原始链接颜色 border-bottom: none; border-bottom: 1px solid #0593d3; //底部分割线颜色 &amp;:hover &#123; color: #fc6423; //鼠标经过颜色 border-bottom: none; border-bottom: 1px solid #fc6423; //底部分割线颜色 &#125;&#125; 文章末尾添加“文章结束”标记在themes/next/layout/_macro/目录下新建passage-end-tag.swig，填入如下内容：12345&lt;div&gt; &#123;% if not is_index %&#125; &lt;div style="text-align:center;color: #ccc;font-size:14px;"&gt;-------------本文结束&lt;i class="fa fa-paw"&gt;&lt;/i&gt;感谢您的阅读-------------&lt;/div&gt; &#123;% endif %&#125;&lt;/div&gt; 然后编辑themes/next/layout/_macro/post.swig，按照下图添加代码块：12345&lt;div&gt; &#123;% if not is_index %&#125; &#123;% include 'passage-end-tag.swig' %&#125; &#123;% endif %&#125;&lt;/div&gt; 最后编辑themes/next/_config.yml，添加如下内容：123# 文章末尾添加“本文结束”标记passage_end_tag: enabled: true 添加网页加载进度条打开themes/next/_config.yml，搜索“pace:”，设置为true。1pace: true 设置文章的显示顺序编辑node_modules/hexo-generator-index/lib/generator.js，在return之前添加如下代码：12345678910111213posts.data = posts.data.sort(function(a, b) &#123;if(a.top &amp;&amp; b.top) &#123; // 两篇文章top都有定义 if(a.top == b.top) return b.date - a.date; // 若top值一样则按照文章日期降序排 else return b.top - a.top; // 否则按照top值降序排&#125;else if(a.top &amp;&amp; !b.top) &#123; // 以下是只有一篇文章top有定义，那么将有top的排在前面（这里用异或操作居然不行233） return -1;&#125;else if(!a.top &amp;&amp; b.top) &#123; return 1;&#125;else return b.date - a.date; // 都没定义按照文章日期降序排&#125;) 然后在每篇文章的头部添加top字段，top值越大的文章显示越靠前。12345678---title: Hexo+Github博客最简教程-Dockerfile自动搭建date: 2019-04-18 15:23:05top: 6tags: [Hexo, Dockerfile, Linux, Github]categories: [IDE]copyright: ture--- 添加底部的小图标打开themes/next/layout/_partials/footer.swig搜索with-love，修改为如下代码。从fontawesom选择你喜欢的图标名称，我这里选择的是heart。123&lt;span class="with-love" id="animate"&gt; &lt;i class="fa fa-heart" aria-hidden = "true"&gt;&lt;/i&gt;&lt;/span&gt; 文章底部添加版权信息在themes/next/layout/_macro/下新建 my-copyright.swig，填入如下内容：123456789101112131415161718192021222324252627282930&#123;% if page.copyright %&#125;&lt;div class="my_post_copyright"&gt; &lt;script src="//cdn.bootcss.com/clipboard.js/1.5.10/clipboard.min.js"&gt;&lt;/script&gt; &lt;!-- JS库 sweetalert 可修改路径 --&gt; &lt;script src="https://cdn.bootcss.com/jquery/2.0.0/jquery.min.js"&gt;&lt;/script&gt; &lt;script src="https://unpkg.com/sweetalert/dist/sweetalert.min.js"&gt;&lt;/script&gt; &lt;p&gt;&lt;span&gt;本文标题:&lt;/span&gt;&lt;a href="&#123;&#123; url_for(page.path) &#125;&#125;"&gt;&#123;&#123; page.title &#125;&#125;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;span&gt;文章作者:&lt;/span&gt;&lt;a href="/" title="访问 &#123;&#123; theme.author &#125;&#125; 的个人博客"&gt;&#123;&#123; theme.author &#125;&#125;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;span&gt;发布时间:&lt;/span&gt;&#123;&#123; page.date.format("YYYY年MM月DD日 - HH:MM") &#125;&#125;&lt;/p&gt; &lt;p&gt;&lt;span&gt;最后更新:&lt;/span&gt;&#123;&#123; page.updated.format("YYYY年MM月DD日 - HH:MM") &#125;&#125;&lt;/p&gt; &lt;p&gt;&lt;span&gt;原始链接:&lt;/span&gt;&lt;a href="&#123;&#123; url_for(page.path) &#125;&#125;" title="&#123;&#123; page.title &#125;&#125;"&gt;&#123;&#123; page.permalink &#125;&#125;&lt;/a&gt; &lt;span class="copy-path" title="点击复制文章链接"&gt;&lt;i class="fa fa-clipboard" data-clipboard-text="&#123;&#123; page.permalink &#125;&#125;" aria-label="复制成功！"&gt;&lt;/i&gt;&lt;/span&gt; &lt;/p&gt; &lt;p&gt;&lt;span&gt;许可协议:&lt;/span&gt;&lt;i class="fa fa-creative-commons"&gt;&lt;/i&gt; &lt;a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank" title="Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)"&gt;署名-非商业性使用-禁止演绎 4.0 国际&lt;/a&gt; 转载请保留原文链接及作者。&lt;/p&gt; &lt;/div&gt;&lt;script&gt; var clipboard = new Clipboard('.fa-clipboard'); $(".fa-clipboard").click(function()&#123; clipboard.on('success', function()&#123; swal(&#123; title: "", text: '复制成功', icon: "success", showConfirmButton: true &#125;); &#125;); &#125;); &lt;/script&gt;&#123;% endif %&#125; 然后在themes/next/source/css/_common/components/post/下新建my-post-copyright.styl，填入如下内容：123456789101112131415161718192021222324252627282930313233343536373839404142434445.my_post_copyright &#123; width: 85%; max-width: 45em; margin: 2.8em auto 0; padding: 0.5em 1.0em; border: 1px solid #d3d3d3; font-size: 0.93rem; line-height: 1.6em; word-break: break-all; background: rgba(255,255,255,0.4);&#125;.my_post_copyright p&#123;margin:0;&#125;.my_post_copyright span &#123; display: inline-block; width: 5.2em; color: #b5b5b5; font-weight: bold;&#125;.my_post_copyright .raw &#123; margin-left: 1em; width: 5em;&#125;.my_post_copyright a &#123; color: #808080; border-bottom:0;&#125;.my_post_copyright a:hover &#123; color: #a3d2a3; text-decoration: underline;&#125;.my_post_copyright:hover .fa-clipboard &#123; color: #000;&#125;.my_post_copyright .post-url:hover &#123; font-weight: normal;&#125;.my_post_copyright .copy-path &#123; margin-left: 1em; width: 1em; +mobile()&#123;display:none;&#125;&#125;.my_post_copyright .copy-path:hover &#123; color: #808080; cursor: pointer;&#125; 接着编辑themes/next/layout/_macro/post.swig文件，按照下图位置添加如下代码：12345&lt;div&gt; &#123;% if not is_index %&#125; &#123;% include 'my-copyright.swig' %&#125; &#123;% endif %&#125;&lt;/div&gt; 接着在themes/next/source/css/_common/components/post/post.styl文件最后添加如下代码：1@import "my-post-copyright" 然后，还需要在文章的头部添加copyright字段：12345678---title: Hexo+Github博客最简教程-Dockerfile自动搭建date: 2019-04-18 15:23:05top: 6tags: [Hexo, Dockerfile, Linux, Github]categories: [IDE]copyright: ture--- 最后，编辑根目录下的_config.yml文件，把url换成你的主页：123456# URL## If your site is put in a subdirectoryurl: https://icoty.github.io # 这里换成你的主页root: /permalink: :year/:month/:day/:title/permalink_defaults: 添加网易云音乐外链登陆网易云音乐网页版；点击个人头像“我的主页”；然后能够看到“我创建的歌单”，如果没有则创建一个歌单；选中一个歌单点进去，能够看到“歌曲列表”，点击“歌曲列表”右边的“生成外链播放器”；然后点击右下角的“复制代码”，粘贴到themes/next/layout/_macro/sidebar.swig文件中指定的位置即可，我的是放在侧栏中”友链”下面的。 设置文章缩略显示编辑themes/next/_config.yml，搜索auto_excerpt，设置为true：123456# Automatically Excerpt (Not recommend).# 设置文章不显示全部 点进去再显示全部# Use &lt;!-- more --&gt; in the post to control excerpt accurately.auto_excerpt: enable: true length: 150 自定义代码块样式打开themes\next\source\css_custom\custom.styl，添加如下内容：123456789101112131415// Custom styles.code &#123; color: #ff7600; background: #fbf7f8; margin: 2px;&#125;// 大代码块的自定义样式.highlight, pre &#123; margin: 5px 0; padding: 5px; border-radius: 3px;&#125;.highlight, code, pre &#123; border: 1px solid #d6d6d6;&#125; 把一篇文章归为多类如下会把该文章归为Linux/IPC类。123categories: - Linux - IPC 如下会把该文章归为Linux/IPC和TCP两类。123categories: - [Linux, ICP] - TCP 参考文献https://www.jianshu.com/p/9f0e90cc32c2https://www.jianshu.com/p/bff1b1845ac9]]></content>
      <categories>
        <category>Hexo博客搭建</category>
      </categories>
      <tags>
        <tag>Dockerfile</tag>
        <tag>Hexo命令</tag>
        <tag>镜像</tag>
        <tag>容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[进程间通信-利用共享内存和管道通信实现聊天窗口]]></title>
    <url>%2F2019%2F04%2F18%2Fipc-chat%2F</url>
    <content type="text"><![CDATA[问题模型 A、B两个进程通过管道通信，A 进程每次接收到的数据通过共享内存传递给A1进程显示，同理，B进程每次接收到的数据通过共享内存传递给B1进程显示； 对于A、B 进程，采用ctrl+c（实际为SIGINT信号）方式退出，A、B进程通过捕捉SIGINT信号注册信号处理函数进行资源清理，A1、B1进程手动关闭即可。 特别注意 A、B通过管道通信，如果首先通过ctrl+c退出A进程，那么B进程的fifo1管道的写端会收到SIGPIPE信号而终止B进程，因此必须在B进程终止前清理掉被B占用的共享内存2，将共享内存2的引用计数减一，否则，当B1进程退出并清理共享内存2后，共享内存2的引用计数不为0，会导致共享内存2得不到释放； 为了解决前一个问题，A、B进程在启动后立即将各自的进程id通过管道发送给对方，并在各自的进程退出时向对方进程id发送SIGINT信号，触发对方进程进入信号处理接口执行资源回收工作； A和A1通过共享内存1通信，会从A进程和A1进程的虚拟地址空间分配一段连续的页映射到同一块连续的物理内存页上，这样A、A1两个进程都可以间接访问物理内存页，从而达到通信的目的，一般共享内存需要进行保护，读写不能同时进行，也不能同时进行写操作，共享内存省去了从内核缓冲区到用户缓冲区的拷贝，因此效率高。 编码与效果图 func.h:12345678910111213141516171819202122232425262728293031#include &lt;stdio.h&gt;#include &lt;sys/types.h&gt;#include &lt;fcntl.h&gt;#include &lt;sys/stat.h&gt;#include &lt;unistd.h&gt;#include &lt;errno.h&gt;#include &lt;strings.h&gt;#include &lt;string.h&gt;#include &lt;sys/select.h&gt;#include &lt;sys/time.h&gt;#include &lt;stdlib.h&gt;#include &lt;sys/wait.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/ipc.h&gt;#include &lt;sys/shm.h&gt;#include &lt;netinet/in.h&gt;#include &lt;stdio.h&gt;#include &lt;sys/socket.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;string.h&gt;#include &lt;netdb.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/select.h&gt;#include &lt;sys/time.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/uio.h&gt;#include &lt;sys/stat.h&gt;#include &lt;fcntl.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/ipc.h&gt;#include &lt;sys/shm.h&gt; processA.cpp：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798#include "func.h"int shmid;int pidB; // 存放对端进程B的进程id号char *p; // 共享内存指针// 回收共享内存资源前先杀死对端进程，否则回收失败void handle(int num)&#123; kill(pidB, SIGINT); shmdt(p); int ret; if(-1 == (ret=shmctl(shmid, IPC_RMID, NULL))) &#123; perror("shmctl"); return (void)-1; &#125; exit(0);&#125;int main(int argc, char **argv)&#123; signal(SIGINT, handle); if(-1 == (shmid=shmget(1234, 4096, IPC_CREAT|0666))) &#123; perror("shmget"); return -1; &#125; if((char*)-1 == (p=(char*)shmat(shmid, NULL, 0))) &#123; perror("shmat"); return -1; &#125; // 管道文件为单工通信方式，因此需要建立两条管道 // A进程通过管道文件fifo1的读端fdr读取B进程发送的数据 // A进程通过管道文件fifo2的写端fdw向B进程发送数据 int fdr, fdw; if(-1 == (fdr=open("fifo1", O_RDONLY)) || -1 == (fdw=open("fifo2", O_WRONLY))) &#123; perror("open fifo1 or open fifo2"); return -1; &#125; // 通信之前先通过管道互相告知对方自己的进程id char s1[10] = &#123;0&#125;; char s2[10] = &#123;0&#125;; sprintf(s1, "%d\n", getpid()); write(fdw, s1, strlen(s1) - 1); read(fdr, s2, strlen(s1) - 1); pidB = atoi(s2); printf("pipe connect success, A to A1 shmid:[%d], pidA:[%d], pidB:[%d]\n", shmid, getpid(), pidB); char buf[1024] = &#123;0&#125;; int ret; fd_set rdset; while(true) &#123; FD_ZERO(&amp;rdset); FD_SET(0, &amp;rdset); FD_SET(fdr, &amp;rdset); if((ret=select(fdr+1, &amp;rdset, NULL, NULL, NULL) &gt; 0)) &#123; // fdr可读,则接收数据之后通过共享内存传给A1 if(FD_ISSET(fdr, &amp;rdset)) &#123; bzero(buf, sizeof(buf)); if(read(fdr, buf, sizeof(buf)) &gt; 0) &#123; strncpy(p, buf, sizeof(buf)); &#125; else &#123; break; &#125; &#125; // 标准输入可读,读出来传递给B进程 if(FD_ISSET(0, &amp;rdset)) &#123; bzero(buf, sizeof(buf)); if(read(STDIN_FILENO, buf, sizeof(buf)) &gt; 0) &#123; write(fdw, buf, strlen(buf) - 1); &#125; else &#123; break; &#125; &#125; &#125; &#125; close(fdr); close(fdw); return 0;&#125; processB.cpp：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798#include "func.h"int shmid;int pidA; // 存放对端进程idchar *p; // 共享内存指针// 回收共享内存资源前先杀死对端进程，否则回收失败void handle(int num)&#123; kill(pidA, SIGINT); shmdt(p); int ret; if(-1 == (ret=shmctl(shmid, IPC_RMID, NULL))) &#123; perror("shmctl"); return (void)-1; &#125; exit(0);&#125;int main(int argc, char **argv)&#123; signal(SIGINT, handle); if(-1 == (shmid=shmget(1235, 4096, IPC_CREAT|0666))) &#123; perror("shmget"); return -1; &#125; if((char*)-1 == (p=(char*)shmat(shmid, NULL, 0))) &#123; perror("shmat"); return -1; &#125; // 管道文件为单工通信方式 // B进程通过管道文件fifo1的写端fdw向A进程发送数据 // B进程通过管道文件fifo2的读端fdr接收A进程的数据 int fdr, fdw; if(-1 == (fdw=open("fifo1", O_WRONLY)) || -1 == (fdr=open("fifo2", O_RDONLY))) &#123; perror("open fifo1 or open fifo2"); return -1; &#125; // 通信之前先通过管道互相告知对方自己的进程id char s1[10] = &#123;0&#125;; char s2[10] = &#123;0&#125;; sprintf(s1, "%d\n", getpid()); write(fdw, s1, strlen(s1) - 1); read(fdr, s2, strlen(s1) - 1); pidA = atoi(s2); printf("pipe connect success, B to B1 shmid:[%d], pidA:[%d], pidB:[%d]\n", shmid, pidA, getpid()); char buf[1024] = &#123;0&#125;; int ret; fd_set rdset; while(true) &#123; FD_ZERO(&amp;rdset); FD_SET(0, &amp;rdset); FD_SET(fdr, &amp;rdset); if((ret=select(fdr+1, &amp;rdset, NULL, NULL, NULL) &gt; 0)) &#123; // fdr可读,则接收数据之后通过共享内存传给B1 if(FD_ISSET(fdr, &amp;rdset)) &#123; bzero(buf, sizeof(buf)); if(read(fdr, buf, sizeof(buf)) &gt; 0) &#123; strncpy(p, buf, sizeof(buf)); &#125; else &#123; break; &#125; &#125; // 标注输入可读,读出来传递给A进程 if(FD_ISSET(0, &amp;rdset)) &#123; bzero(buf, sizeof(buf)); if(read(STDIN_FILENO, buf, sizeof(buf)) &gt; 0) &#123; write(fdw, buf, strlen(buf) - 1); &#125; else &#123; break; &#125; &#125; &#125; &#125; close(fdr); close(fdw); return 0;&#125; processA1.cpp：123456789101112131415161718192021222324252627282930313233343536373839404142#include "fuprintf("p:%s\n", p);nc.h"int main(void)&#123; char buf[1024] = &#123;0&#125;; int shmid; if(-1 == (shmid=shmget(1234, 4096, IPC_CREAT|0666))) &#123; perror("shmget"); return -1; &#125; char *p; if((char*)-1 == (p=(char*)shmat(shmid, NULL, 0))) &#123; perror("shmat"); return -1; &#125; while(true) &#123; if(!(strcmp(buf, p))) &#123; continue; &#125; else &#123; // 共享内存有数据可读 bzero(buf, sizeof(buf)); strcpy(buf, p); printf("I am A1, recv from A:[%s]\n", buf); &#125; &#125; if(-1 ==(shmctl(shmid, IPC_RMID, 0))) &#123; perror("shmctl"); return -1; &#125; return 0;&#125; processB1.cpp：123456789101112131415161718192021222324252627282930313233343536373839404142#include "func.h"int main(void)&#123; char buf[1024] = &#123;0&#125;; int shmid; if(-1 == (shmid=shmget(1235, 4096, IPC_CREAT|0666))) &#123; perror("shmget"); return -1; &#125; char *p; if((char*)-1 == (p=(char*)shmat(shmid, NULL, 0))) &#123; perror("shmat"); return -1; &#125; while(true) &#123; if(!(strcmp(buf, p))) &#123; continue; &#125; else &#123; // 共享内存有数据可读 bzero(buf, sizeof(buf)); strcpy(buf, p); printf("I am B1, recv from B:[%s]\n", buf); &#125; &#125; if(-1 ==(shmctl(shmid, IPC_RMID, 0))) &#123; perror("shmctl"); return -1; &#125; return 0;&#125; 回收资源 这里首先通过ctrl+c退出A进程，然后B进程收到SIGPIPE信号退出，A、B进程同时调用各自的信号处理函数回收资源，通过ipcs命令发现拥有者为root的共享内存资源的nattch都为1，分别被A1和B1占有。 然后手动关闭A1、B1进程，再次执行ipcs命令，发现拥有者为root的共享内存资源不存在，已经释放成功。1$ ipcs # 查看共性内存资源数量 源码获取本文所有源码链接]]></content>
      <categories>
        <category>同步机制</category>
        <category>进程间通信</category>
        <category>IO多路复用模型</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>共享内存</tag>
        <tag>命名管道</tag>
        <tag>信号</tag>
        <tag>Select</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下Docker快速部署LAMP]]></title>
    <url>%2F2019%2F04%2F16%2Fdocker-lamp%2F</url>
    <content type="text"><![CDATA[若你的mac或Linux环境上未安装Docker，请移步Docker安装，确认安装成功之后再进行下文内容。如果你不了解Docker如何操作，但是你又想彻底弄懂Docker命令，可以看我另一篇文章Docker最简教程。 拿来即用获取LAMPLAMP镜像我已经搭建好并且我已经测试过了，没有问题。你只需要直接拿去用，执行如下命令：123$docker pull icoty1/lamp:v1.1.0$docker images # 能够看到icoty1/lamp:v1.1.0已经被拉到你本地$docker run -d -ti -p 80:80 -p 3306:3306 -v /Users/yangyu/app/:/var/www/html/ icoty1/lamp:v1.1.0 /bin/bash start.sh # 运行一个容器，目录/Users/yangyu/app/是你本机PHP应用位置 /Users/yangyu/app/下存放的是public、thinkphp、vendor、runtime等内容。然后访问http://localhost 能够看到PHP应用目录下的内容，如下图，说明已经成功。 然后访问http://localhost/public/index.php ，这个是PHP的入口。如果浏览器打开提示权限不够，不要慌，检查下你无法访问的那个目录下是否存在.htaccess文件，如果有则删除就好了，如果没有则执行如下命令。 123$docker exec -it [CONTAINER ID] /bin/bash # 进入前面启动的容器中$chmod -R 0777 /var/www/html/ # 赋予最高权限$sh start.sh # start.sh在根目录下，是重启服务用的 访问phpadmin：http://localhost/phpmyadmin/index.php ，登陆的用户名和密码均为phpmyadmin，登陆后你能够在浏览器上一目了然的对所有数据表进行操作。 容器内根目录下有个start.sh文件，每次需要重启apache服务和mysql服务时只需要执行这个脚本就好了，命令如下： 1$sh start.sh LAMP版本Ubuntu 18.04.2，PHP 7.2.15，mysql 5.7.25，同时也安装了phpmyadmin。下面是查看版本的命令。mysql数据库的root账户密码是root，phpmyadmin账户密码是phpmyadmin ，你可以把密码修改成你的，mysql修改用户密码。 12345678910111213root@4f5e11ebccac:/# cat /etc/issueUbuntu 18.04.2 LTS \n \lroot@4f5e11ebccac:/# php -vPHP 7.2.15-0ubuntu0.18.04.2 (cli) (built: Mar 22 2019 17:05:14) ( NTS )Copyright (c) 1997-2018 The PHP GroupZend Engine v3.2.0, Copyright (c) 1998-2018 Zend Technologies with Zend OPcache v7.2.15-0ubuntu0.18.04.2, Copyright (c) 1999-2018, by Zend Technologiesroot@4f5e11ebccac:/# mysql -u root -pEnter password: Welcome to the MySQL monitor. Commands end with ; or \g.Your MySQL connection id is 9Server version: 5.7.25-0ubuntu0.18.04.2 (Ubuntu) 到这里你的目的就已经达到了，一个完整LAMP服务已经在你本机上跑起来并且能用了。下面的内容是我制作icoty1/lamp:v1.1.0的过程，如果你有兴趣，或者想知道我是怎么制作出来的，欢迎继续围观。 icoty1/lamp:v1.1.0制作过程获取ubuntu基础镜像1$ docker pull i icoty1/ubuntu:18.04.2-LTS # 从icoty1仓库拉取基础镜像并运行一个容器 安装依赖进入前面运行的容器中安装接下来的内容。 mysql12345$apt-get update$apt-get upgrade -y $apt-get dist-upgrade -y$apt-get install vim -y$apt-get install mysql-server mysql-client -y apache/php12345$apt-get install apache2 -y$vi /etc/apache2/apache2.conf # 添加 ServerName localhost:80$apt-get install php7.2 -y # 这个过程中需要选择国家和时区，如图。$apt-get install libapache2-mod-php7.2$apt-get install php7.2-mysql -y phpmyadmin123$apt-get install php-mbstring php7.0-mbstring php-gettext$service apache2 restart$apt-get install phpmyadmin # 这个过程中会自动创建mysql用户名phpmyadmin，需要手动输入密码，如图。 使apache解析php文件 vi /etc/apache2/apache2.conf，添加如下内容，让apache服务知道libphp7.2.so库在哪里，找不到这个动态库就无法解析php文件。1234# add by yangyu, current dictory is '/etc/apache2/', so '../../usr/lib/apache2/modules/libphp7.2.so' = '/usr/lib/apache2/modules/libphp7.2.so'LoadModule php7_module ../../usr/lib/apache2/modules/libphp7.2.soAddType application/x-httpd-php .phpDirectoryIndex index.php index.htm index.html 到此，这个容器内已经搭建好了LAMP服务，使用docker commit命令把这个容器提交为镜像icoty1/lamp:v1.1.0，然后push到我的docker hub仓库上，你所pull的正是我push上去的。 参考文献https://www.cnblogs.com/impy/p/8040684.html # lamphttps://linux.cn/article-7463-1.html # lamphttps://blog.csdn.net/longgeaisisi/article/details/78448525 # lamphttps://www.cnblogs.com/mmx8861/p/9062363.html # mysql密码修改]]></content>
      <categories>
        <category>Docker搭建LAMP</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Docker命令</tag>
        <tag>Dockerfile</tag>
      </tags>
  </entry>
</search>
